{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from docling.document_converter import DocumentConverter\n",
    "from tqdm import tqdm\n",
    "from flock.core.tools.basic_tools import extract_links_from_markdown, get_web_content_as_markdown\n",
    "# load all markdown file in news folder\n",
    "import glob\n",
    "import chromadb\n",
    "from devtools import debug, pprint\n",
    "from flock.core.tools.llm_tools import chunk_text_for_embedding\n",
    "import random\n",
    "from flock.core import FlockFactory\n",
    "from flock.core.logging.formatters.themes import OutputTheme\n",
    "from flock.evaluators.memory.memory_evaluator import MemoryEvaluator, MemoryEvaluatorConfig\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from ragas.testset.graph import KnowledgeGraph\n",
    "from ragas.testset.graph import Node, NodeType\n",
    "from ragas.llms.base import llm_factory\n",
    "from ragas.embeddings.base import embedding_factory\n",
    "from ragas.testset.transforms import Parallel, apply_transforms\n",
    "from ragas.testset.transforms import (\n",
    "    HeadlinesExtractor,\n",
    "    HeadlineSplitter,\n",
    "    KeyphrasesExtractor,\n",
    "    OverlapScoreBuilder,\n",
    ")\n",
    "from dataclasses import dataclass\n",
    "import typing as t\n",
    "from ragas.testset.synthesizers.multi_hop.base import (\n",
    "    MultiHopQuerySynthesizer,\n",
    "    MultiHopScenario,\n",
    ")\n",
    "from IPython.display import clear_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEWS import\n",
    "import os\n",
    "\n",
    "\n",
    "path = \"https://lite.cnn.com\"\n",
    "\n",
    "index_markdown = get_web_content_as_markdown(path)\n",
    "links = extract_links_from_markdown(index_markdown,path)\n",
    "\n",
    "# create news folder if it doesn't exist\n",
    "if not os.path.exists(\"news\"):\n",
    "    os.makedirs(\"news\") \n",
    "\n",
    "\n",
    "converter = DocumentConverter()\n",
    "for link in tqdm(links):\n",
    "    try:    \n",
    "        result = converter.convert(link)\n",
    "        markdown = result.document.export_to_markdown()\n",
    "        with open(f\"news/{link.split('/')[-2]}.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(markdown)\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting {link}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Embeddings and Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "news_files = glob.glob(\"news/*.md\")\n",
    "news_files = [open(file, \"r\", encoding=\"utf-8\") for file in news_files]\n",
    "news_files = [(file.read(),file.name) for file in news_files]\n",
    "\n",
    "news_files_chunks = []\n",
    "for file_content, file_name in tqdm(news_files):\n",
    "    news_files_chunks.extend(chunk_text_for_embedding(file_content, file_name.split(\"\\\\\")[-1], chunk_size=2000, overlap=250))\n",
    "\n",
    "clear_output(wait=True) \n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\".chroma\")\n",
    "collection = chroma_client.get_or_create_collection(name=\"my_cnn_news\")        \n",
    "for chunk in tqdm(news_files_chunks):\n",
    "    collection.add(\n",
    "        ids=[chunk[\"chunk_id\"]],\n",
    "        documents=[chunk[\"text\"]],\n",
    "        metadatas=[{\"source\": chunk[\"file\"]}],\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.PersistentClient(path=\".chroma\")\n",
    "collection = chroma_client.get_or_create_collection(name=\"my_cnn_news\")        \n",
    "\n",
    "query=\"What is the vaccination rate goal set by HHS to help prevent outbreaks of measles?\"\n",
    "results = collection.query(query_texts=[query], n_results=3)\n",
    "debug(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Queries with Flock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.PersistentClient(path=\".chroma\")\n",
    "collection = chroma_client.get_or_create_collection(name=\"my_cnn_news\")\n",
    "entries = collection.get()\n",
    "# Get 10 random entries from the collection\n",
    "random_ids = random.sample(entries.get(\"ids\"), 10)\n",
    "random_news_chunks = collection.get(ids=random_ids).get(\"documents\")\n",
    "\n",
    "# Easiest form of query - answer a question based on the chunk\n",
    "simple_qa_generator = FlockFactory.create_default_agent(name=\"simple_qa_generator\",\n",
    "                                                     model=\"openai/gpt-4o\",\n",
    "                                                     input=\"rag_context: str\",\n",
    "                                                     output=\"factoid_question: str, factoid_answer: str\",\n",
    "                                                     enable_rich_tables=True)\n",
    "\n",
    "for news_chunk in random_news_chunks: \n",
    "    qa_pair = await simple_qa_generator.run_async(inputs={\"rag_context\": news_chunk})\n",
    "    print(qa_pair)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More complex form of query - answer a question based on the whole document\n",
    "# get 10 random news markdown files from the news folder\n",
    "\n",
    "news_files = glob.glob(\"news/*.md\")\n",
    "news_files = [open(file, \"r\", encoding=\"utf-8\") for file in news_files]\n",
    "news_files = [(file.read(),file.name) for file in news_files]\n",
    "random_news_files = random.sample(news_files, 10)\n",
    "\n",
    "simple_qa_generator = FlockFactory.create_default_agent(name=\"simple_qa_generator\",\n",
    "                                                     model=\"openai/gpt-4o\",\n",
    "                                                     input=\"rag_context: str\",\n",
    "                                                     output=\"factoid_question: str, factoid_answer: str, ground_truth: str\",\n",
    "                                                     enable_rich_tables=True)\n",
    "\n",
    "# let the agent iterate over the news files and generate a question and answer for each file    \n",
    "for news_file in random_news_files: \n",
    "    qa_pair = await simple_qa_generator.run_async(inputs={\"rag_context\": news_file})\n",
    "    print(qa_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "news_files = glob.glob(\"news/*.md\")\n",
    "news_files = [open(file, \"r\", encoding=\"utf-8\") for file in news_files]\n",
    "news_files = [(file.read(),file.name) for file in news_files]\n",
    "\n",
    "write_to_kg_agent = FlockFactory.create_default_agent(model=\"openai/gpt-4o\",name=\"news_to_kg_agent\", \n",
    "                                            input=\"data\", \n",
    "                                            output_theme=OutputTheme.aardvark_blue, shorten_long_lists=True)\n",
    "\n",
    "\n",
    "write_to_kg_agent.evaluator = MemoryEvaluator(name=\"news_to_kg_agent\", \n",
    "                                              config=MemoryEvaluatorConfig(splitting_mode=\"characters\", \n",
    "                                                                           number_of_concepts_to_extract=3))\n",
    "\n",
    "for file_content, file_name in news_files:\n",
    "    result = write_to_kg_agent.run(inputs={\"data\": file_content})\n",
    "    print(result)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
