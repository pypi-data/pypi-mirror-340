# Core dependencies
torch>=2.0.0
transformers>=4.30.0
fastapi>=0.95.0
uvicorn>=0.22.0
pydantic>=1.10.0
requests>=2.28.0
tqdm>=4.64.0
py-cpuinfo>=9.0.0
bitsandbytes>=0.40.0
psutil>=5.9.0
accelerator>=0.20.0
huggingface_hub>=0.16.0

# For TPU support
# Install PyTorch with XLA support:
# pip install torch~=2.6.0 'torch_xla[tpu]~=2.6.0' \
#   -f https://storage.googleapis.com/libtpu-releases/index.html \
#   -f https://storage.googleapis.com/libtpu-wheels/index.html

# For GGUF model support
llama-cpp-python==0.2.25
cmake==3.26.4
ninja

# Environment variables for TPU
# export PJRT_DEVICE=TPU
# export XLA_PYTHON_CLIENT_PREALLOCATE=false