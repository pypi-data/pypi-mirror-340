{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms\n",
    "\n",
    "{class}`~kliff.transforms` is a collection of commonly used functions, used to change or transform, the datasets/parameters. Transforms module is divided as,\n",
    " - Coordinate transforms: Mapping the coordinates of a configuration to invariant representations, which can be used in ML models.\n",
    "     - Descriptors\n",
    "     - Radial Graphs\n",
    " - Properties: Transform properties associated with the configurations. Often it takes input as a complete dataset, and aggregate statistics of property of entire dataset before transformations like normalization\n",
    " - Parameters:**Only available for the physic based models for now** Transform the parameter space for enabling better sampling/training.[ref]\n",
    "\n",
    "\n",
    "## Configuration Transforms\n",
    "\n",
    "### Descriptor\n",
    "The `Descriptors` module bridges the [libdescriptor](https://github.com/openkim/libdescriptor) library with KLIFF’s data structures (i.e., `Configuration`, `NeighborList`). It provides:\n",
    "\n",
    "- `show_available_descriptors()`: A helper function that prints all descriptor names.\n",
    "- `Descriptor`: \n",
    "  - Takes a `cutoff`, `species`, `descriptor name`, and `hyperparameters`.\n",
    "  - Computes descriptors (`forward`) and their derivatives w.r.t. atomic coordinates (`backward`).\n",
    "  - Can store results directly in the `Configuration` object’s fingerprint.\n",
    "- `default_hyperparams`: Module containing collection of sane defaults for different descriptors\n",
    "\n",
    "```{tip}\n",
    "This module relies on the optional dependency `libdescriptor`. Which can be installed as `conda install ipcamit::libdescriptor` for now.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Descriptors below are currently available, select them by `descriptor: str` attribute:\n",
      "--------------------------------------------------------------------------------\n",
      "SymmetryFunctions\n",
      "Bispectrum\n",
      "SOAP\n",
      "Xi\n"
     ]
    }
   ],
   "source": [
    "from kliff.transforms.configuration_transforms.descriptors import show_available_descriptors\n",
    "show_available_descriptors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kliff.transforms.configuration_transforms.descriptors import Descriptor\n",
    "from kliff.transforms.configuration_transforms.default_hyperparams import symmetry_functions_set30\n",
    "\n",
    "desc = Descriptor(cutoff=3.77, \n",
    "                  species=[\"Si\"], \n",
    "                  descriptor=\"SymmetryFunctions\", \n",
    "                  hyperparameters=symmetry_functions_set30())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `Descriptor` module is designed to work as a thin wrapper over `libdescriptor` library, and provides `forward` and `backward` function for computing the descriptors, and their vector-Jacobian products for gradient. Given below is a brief overview of how typical ML potential evaluates forces, and how it is achieved in KLIFF.\n",
    "\n",
    "#### Theory of ML with descriptors\n",
    "Descriptors ($\\zeta$) are used in machine learning to transform raw input features ($\\mathbf{\\zeta}$) into a higher-dimensional representation that captures more complex patterns and relationships. This transformation is particularly useful in various applications, including molecular dynamics, material science, and geometric deep learning.\n",
    "\n",
    "#### Forward Pass\n",
    "\n",
    "1. Descriptor Calculation\n",
    "   - The input features $x$ (e.g., atomic coordinates, molecular structures) are mapped to a higher-dimensional space using a function $F$.\n",
    "   - The output of this mapping is the descriptor $\\mathbf{\\zeta}$:\n",
    "\n",
    "$$\n",
    "     \\mathbf{\\zeta} = F(\\mathbf{x})\n",
    "$$\n",
    "\n",
    "2. Model Prediction:\n",
    "   - The descriptor $\\zeta$ is then used as input to a machine learning model (e.g., neural network) to make predictions:\n",
    "\n",
    "$$\n",
    "     y = \\text{ML Model}(\\mathbf{\\zeta})\n",
    "$$\n",
    "\n",
    "##### Backward Pass\n",
    "\n",
    "1. Loss Calculation:\n",
    "   - A loss function measures the difference between the model's predictions and the ground truth:\n",
    "\n",
    "$$\n",
    "     \\mathcal{L} = \\text{Loss}(y, \\text{ground truth})\n",
    "$$\n",
    "\n",
    "2. Derivative of Loss with Respect to Descriptors:\n",
    "   - During backpropagation, the first step is to compute the derivative of the loss with respect to the descriptors:\n",
    "\n",
    "$$\n",
    "     \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{\\zeta}} = \\nabla_\\mathbf{\\zeta} \\mathcal{L}\n",
    "$$\n",
    "\n",
    "3. Vector-Jacobian Product:\n",
    "   - The next step is to compute the derivative of the descriptors with respect to the input coordinates $\\mathbf{x}$. This is represented by the Jacobian matrix:\n",
    "\n",
    "$$\n",
    "     J = \\frac{\\partial \\mathbf{\\zeta}}{\\partial \\mathbf{x}} = \\nabla_x F(x)\n",
    "$$\n",
    "\n",
    "   - To efficiently compute the gradient of the loss with respect to the input $\\mathbf{x}$, we use the vector-Jacobian product:\n",
    "     \n",
    "$$\n",
    "     \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{x}} = J \\cdot \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{\\zeta}}\n",
    "$$\n",
    "\n",
    "4. Gradient Flow:\n",
    "   - The gradients are then used to update the model parameters during optimization (e.g., gradient descent):\n",
    "\n",
    "$$\n",
    "     \\text{Parameters} \\leftarrow \\text{Parameters} - \\eta \\frac{\\partial \\mathcal{L}}{\\partial x}\n",
    "$$\n",
    "\n",
    "where $\\eta$ is the learning rate.\n",
    "\n",
    "#### Forces\n",
    "\n",
    "Forces for an ML model can be evaluated similary\n",
    "\n",
    "$$\n",
    "\\mathbf{\\mathcal{F}} = - \\frac{\\partial E}{\\partial \\mathbf{\\zeta}} \\cdot \\frac{\\partial \\mathbf{\\zeta}}{\\partial \\mathbf{x}}\n",
    "$$\n",
    "\n",
    "See example below.\n",
    "\n",
    "#### KLIFF Descriptor `backward` and `forward`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0. -0. -0.]\n",
      " [-0. -0. -0.]]\n"
     ]
    }
   ],
   "source": [
    "# generate Si configuration\n",
    "from ase.build import bulk\n",
    "from kliff.dataset import Configuration\n",
    "import numpy as np\n",
    "\n",
    "Si_diamond = bulk(\"Si\", a=5.44)\n",
    "Si_config = Configuration.from_ase_atoms(Si_diamond)\n",
    "\n",
    "# FORWARD: generating the descriptor $\\zeta$\n",
    "zeta = desc.forward(Si_config)\n",
    "\n",
    "# BACKWARD: vector-jacobian product against arbitrary vector (\\partial L/\\partial \\zeta)\n",
    "dE_dZeta = np.random.random(zeta.shape)\n",
    "\n",
    "forces = - desc.backward(Si_config, dE_dZeta=dE_dZeta)\n",
    "print(forces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radial Graphs\n",
    "\n",
    "Similarly users can also generate radial graphs for graph neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyGGraph(energy=0.0, forces=[2, 3], n_layers=1, coords=[54, 3], images=[54], species=[54], z=[54], cell=[9], contributions=[54], num_nodes=54, idx=-1, edge_index0=[2, 14])\n"
     ]
    }
   ],
   "source": [
    "from kliff.transforms.configuration_transforms.graphs import RadialGraph\n",
    "\n",
    "graph_generator = RadialGraph(species=[\"Si\"], cutoff=3.77, n_layers=1)\n",
    "\n",
    "# dummy energy, needed for eval\n",
    "Si_config._energy = 0.0\n",
    "Si_config._forces = np.zeros_like(Si_config.coords)\n",
    "\n",
    "print(graph_generator.forward(Si_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
