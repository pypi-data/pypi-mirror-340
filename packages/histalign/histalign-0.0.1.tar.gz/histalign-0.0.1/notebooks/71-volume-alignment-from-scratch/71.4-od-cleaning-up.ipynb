{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-10T14:57:31.041131Z",
     "start_time": "2025-04-10T14:57:31.036030Z"
    }
   },
   "source": [
    "from collections.abc import Sequence\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import re\n",
    "from typing import Any\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import nrrd\n",
    "import numpy as np\n",
    "import pydantic\n",
    "from scipy.spatial.distance import euclidean\n",
    "import vedo\n",
    "\n",
    "from histalign.backend.io import gather_alignment_paths, load_image\n",
    "from histalign.backend.maths import (\n",
    "    apply_rotation,\n",
    "    compute_centre,\n",
    "    compute_normal,\n",
    "    compute_normal_from_raw,\n",
    "    compute_origin,\n",
    ")\n",
    "from histalign.backend.models import AlignmentSettings, VolumeSettings\n",
    "from histalign.backend.registration import Registrator\n",
    "from histalign.backend.registration.alignment import (\n",
    "    replace_path_parts,\n",
    ")\n",
    "\n",
    "vedo.settings.default_backend = \"vtk\""
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:57:31.099928Z",
     "start_time": "2025-04-10T14:57:31.095634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PathType = str | Path\n",
    "\n",
    "ALIGNMENT_FILE_NAME_PATTERN = re.compile(r\"[0-9a-f]{32}\\.json\")\n",
    "_SUPPORTED_TYPES = [\".h5\", \".hdf5\", \".nrrd\", \".json\"]\n",
    "\n",
    "\n",
    "def imshow(image: np.ndarray) -> None:\n",
    "    plt.imshow(image)\n",
    "    plt.axis(False)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show(objects: object | Sequence[object], axes: int = 3) -> None:\n",
    "    try:\n",
    "        objects = [] + objects\n",
    "    except TypeError:\n",
    "        objects = [objects]\n",
    "\n",
    "    vedo.show(\n",
    "        objects,\n",
    "        axes=3,\n",
    "        interactive=False,\n",
    "    ).interactive().close()\n",
    "\n",
    "\n",
    "def load_file(path: PathType) -> Any:\n",
    "    path = Path(path)\n",
    "    if (suffix := path.suffix) not in _SUPPORTED_TYPES:\n",
    "        raise ValueError(\n",
    "            f\"File extension not supported. Received: {suffix}. Allowed: {' '.join(_SUPPORTED_TYPES)}\"\n",
    "        )\n",
    "\n",
    "    if suffix == \".json\":\n",
    "        data = json.load(path.open())\n",
    "    elif suffix == \".nrrd\":\n",
    "        data = nrrd.read(path)[0]\n",
    "    elif suffix in [\".h5\", \".hdf5\"]:\n",
    "        with h5py.File(path) as handle:\n",
    "            data = handle[list(handle.keys())[0]][:]\n",
    "\n",
    "    return data"
   ],
   "id": "67eea13cda59de22",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:57:31.192944Z",
     "start_time": "2025-04-10T14:57:31.155750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "atlas_path = \"/home/ediun/.local/share/histalign/atlases/average_template_100.nrrd\"\n",
    "atlas_array = load_file(atlas_path)\n",
    "atlas_volume = vedo.Volume(atlas_array)"
   ],
   "id": "99c5e04f781fd66e",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Building an alignment volume\n",
    "\n",
    "1. Receive path to the alignment directory.\n",
    "2. Collect alignment paths.\n",
    "3. Loop over the paths.\n",
    "    1. Load the alignment settings.\n",
    "    2. Apply regex substitution.\n",
    "    3. Load the file.\n",
    "    4. Compute the origin and normal of the alignment.\n",
    "    5. Check dimensionality.\n",
    "    6. If 2D:\n",
    "        1. Generate point cloud from origin, normal, and shape.\n",
    "        2. Interpolate data into the master volume.\n",
    "    7. If 3D:\n",
    "        1. Compute origin for each Z-slice.\n",
    "        2. Treat as-if 2D."
   ],
   "id": "4728d2bfb16f33ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:57:31.221897Z",
     "start_time": "2025-04-10T14:57:31.218382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_point_cloud(\n",
    "    origin: Sequence[float], shape: Sequence[int], settings: VolumeSettings\n",
    ") -> vedo.Points:\n",
    "    # Build a plane assuming no rotations\n",
    "    plane = vedo.Plane(\n",
    "        pos=(0, 0, 0),\n",
    "        normal=compute_normal_from_raw(0, 0, settings.orientation),\n",
    "        s=shape,\n",
    "    )\n",
    "\n",
    "    # Extract the four corners of the plane\n",
    "    p0, p1, _, p3 = plane.points\n",
    "\n",
    "    # Compute the normals of two orthogonal edges\n",
    "    normal1 = (p0 - p1) / euclidean(p1, p0)\n",
    "    normal2 = (p3 - p1) / euclidean(p1, p3)\n",
    "\n",
    "    # Apply alignment rotation on normals\n",
    "    normal1 = apply_rotation(normal1, settings)\n",
    "    normal2 = apply_rotation(normal2, settings)\n",
    "\n",
    "    # Generate a grid of coordinates the same size as the plane\n",
    "    xs, ys = np.meshgrid(\n",
    "        np.linspace(0, round(euclidean(p1, p0)), round(euclidean(p1, p0))),\n",
    "        np.linspace(0, round(euclidean(p1, p3)), round(euclidean(p1, p3))),\n",
    "    )\n",
    "    points = np.vstack([xs.ravel(), ys.ravel()])\n",
    "\n",
    "    # Apply alignment rotation on the points\n",
    "    points = np.dot(np.vstack((normal1, normal2)).T, points).T\n",
    "\n",
    "    # Translate the grid origin to the alignment origin\n",
    "    points += -vedo.Points(points).center_of_mass() + origin\n",
    "\n",
    "    return vedo.Points(points)"
   ],
   "id": "8e87126af9fde375",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:57:34.879976Z",
     "start_time": "2025-04-10T14:57:31.276842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "_module_logger = logging.getLogger(__name__)\n",
    "\n",
    "alignment_directory = Path(\n",
    "    \"/home/ediun/histalign-projects/microns_100_coronal_3d_artificial/bb6ec0f5c8\"\n",
    ")\n",
    "alignment_paths = gather_alignment_paths(alignment_directory)\n",
    "channel_index = \"\"\n",
    "channel_regex = \"\"\n",
    "projection_regex = \"_max\"\n",
    "misc_regexes = []\n",
    "misc_subs = []\n",
    "\n",
    "# Array inside which to store interpolated data from alignment point clouds\n",
    "alignment_array = None\n",
    "# Dummy volume used to query the grid coordinates when interpolating\n",
    "query_volume = None\n",
    "for alignment_path in alignment_paths:\n",
    "    # Load the alignment settings\n",
    "    settings = AlignmentSettings(**json.load(alignment_path.open()))\n",
    "\n",
    "    # Apply regex substitution to the histology path\n",
    "    substituted_path = replace_path_parts(\n",
    "        settings.histology_path,\n",
    "        channel_index,\n",
    "        channel_regex,\n",
    "        projection_regex,\n",
    "        misc_regexes,\n",
    "        misc_subs,\n",
    "    )\n",
    "    try:\n",
    "        settings.histology_path = substituted_path\n",
    "    except pydantic.ValidationError:\n",
    "        _module_logger.warning(\n",
    "            f\"Histology path after regex substitution does not exist \"\n",
    "            f\"(original is '{settings.histology_path}', \"\n",
    "            f\"substituted is '{substituted_path}'). \"\n",
    "            f\"Using the same projected image as was used during registration.\"\n",
    "        )\n",
    "\n",
    "    # Load the image array (allowed to be 2D or 3D)\n",
    "    array = load_image(settings.histology_path, allow_stack=True)\n",
    "    if len(array.shape) not in [2, 3]:\n",
    "        _module_logger.error(\n",
    "            \"Only image arrays with 2 and 3 dimensions (XY and XYZ) are allowed.\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    # Compute the origin and normal as described by the alignment\n",
    "    alignment_origin = compute_origin(\n",
    "        compute_centre(settings.volume_settings.shape), settings.volume_settings\n",
    "    )\n",
    "    alignment_normal = compute_normal(settings.volume_settings)\n",
    "\n",
    "    # List all the 2D images along their origins\n",
    "    images = []\n",
    "    origins = []\n",
    "    # If 2D, only one image and origin\n",
    "    if len(array.shape) == 2:\n",
    "        images = [array]\n",
    "        origins = [alignment_origin]\n",
    "    # If 3D, extract each image and compute its origin\n",
    "    else:\n",
    "        slice_ = [slice(None)] * len(array.shape)\n",
    "        # Assume the Z-dimension is the smallest one\n",
    "        z_dimension_index = array.shape.index(min(array.shape))\n",
    "        z_count = array.shape[z_dimension_index]\n",
    "\n",
    "        # Loop over each Z-slice to extract the images\n",
    "        for index in range(z_count):\n",
    "            slice_[z_dimension_index] = index\n",
    "            images.append(array[tuple(slice_)])\n",
    "\n",
    "        # Loop over multiple of the normal to get origins\n",
    "        for i in range(-int(z_count / 2) + (z_count % 2 == 0), z_count // 2 + 1):\n",
    "            # TODO: Scale multiple by the real Z-spacing (currently assuming same as\n",
    "            #       resolution).\n",
    "            origins.append(alignment_origin + i * alignment_normal)\n",
    "\n",
    "    # Register each image\n",
    "    registrator = Registrator()\n",
    "    for index, origin in enumerate(origins):\n",
    "        image = registrator.get_forwarded_image(\n",
    "            images[index], settings, origin.tolist()\n",
    "        )\n",
    "        images[index] = image\n",
    "\n",
    "    # Loop over each image and generate its 3D point cloud\n",
    "    point_clouds = []\n",
    "    for image, origin in zip(images, origins):\n",
    "        cloud = build_point_cloud(origin, image.shape, settings.volume_settings)\n",
    "\n",
    "        # Insert point data from registered image\n",
    "        cloud.pointdata[\"ImageScalars\"] = image.flatten()\n",
    "\n",
    "        point_clouds.append(cloud)\n",
    "\n",
    "    # Interpolate the point clouds\n",
    "    if alignment_array is None:\n",
    "        alignment_array = np.zeros(settings.volume_settings.shape, dtype=np.uint16)\n",
    "        query_volume = vedo.Volume(alignment_array)\n",
    "\n",
    "    for points in point_clouds:\n",
    "        # Interpolate and store the result in a temporary array\n",
    "        tmp_array = query_volume.interpolate_data_from(points, radius=1).tonumpy()\n",
    "        # tmp_array = query_volume.resample_data_from(points).tonumpy()\n",
    "        tmp_array = np.round(tmp_array).astype(np.uint16)\n",
    "\n",
    "        # TODO: Might be worth thinking of another way to merge. Using the maximum works\n",
    "        #       fine when working with non-overlapping slices but a mean or something\n",
    "        #       more robust might make more sense when tmp_array and\n",
    "        #       interpolation_array have common, non-zero points.\n",
    "        # Merge the new plane into the master array\n",
    "        alignment_array[:] = np.maximum(alignment_array, tmp_array)\n",
    "\n",
    "alignment_volume = vedo.Volume(alignment_array)"
   ],
   "id": "6a4f3b1adddb2cc0",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T14:52:25.544017Z",
     "start_time": "2025-04-10T14:52:18.787997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "show(\n",
    "    [\n",
    "        alignment_volume,\n",
    "        # *point_clouds,\n",
    "        # atlas_volume.alpha(alpha=[0, 0.1]),\n",
    "        # vedo.Points([alignment_origin], r=20, c=\"red\"),\n",
    "        # vedo.Points(origins, r=10, c=\"blue\"),\n",
    "    ]\n",
    ")"
   ],
   "id": "99c75820261fc3fc",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Backups",
   "id": "3426cb9d36a4829c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T13:08:23.907245Z",
     "start_time": "2025-04-10T13:08:20.406718Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 24,
   "source": [
    "_module_logger = logging.getLogger(__name__)\n",
    "\n",
    "alignment_directory = Path(\n",
    "    \"/home/ediun/histalign-projects/microns_100_coronal_3d_artificial/bb6ec0f5c8\"\n",
    ")\n",
    "alignment_paths = gather_alignment_paths(alignment_directory)\n",
    "# alignment_path = alignment_paths[0]\n",
    "channel_index = \"\"\n",
    "channel_regex = \"\"\n",
    "projection_regex = \"_max\"\n",
    "misc_regexes = []\n",
    "misc_subs = []\n",
    "\n",
    "# Array inside which to store interpolated data from alignment point clouds\n",
    "alignment_array = None\n",
    "# Dummy volume used to query the grid coordinates when interpolating\n",
    "query_volume = None\n",
    "for alignment_path in alignment_paths:\n",
    "    ###################################\n",
    "    ### Load the alignment settings ###\n",
    "    ###################################\n",
    "    settings = AlignmentSettings(**json.load(alignment_path.open()))\n",
    "\n",
    "    ################################\n",
    "    ### Apply regex substitution ###\n",
    "    ################################\n",
    "    substituted_path = replace_path_parts(\n",
    "        settings.histology_path,\n",
    "        channel_index,\n",
    "        channel_regex,\n",
    "        projection_regex,\n",
    "        misc_regexes,\n",
    "        misc_subs,\n",
    "    )\n",
    "\n",
    "    # Attempt replacing settings attribute\n",
    "    try:\n",
    "        settings.histology_path = substituted_path\n",
    "    except pydantic.ValidationError:\n",
    "        _module_logger.warning(\n",
    "            f\"Histology path after regex substitution does not exist \"\n",
    "            f\"(original is '{settings.histology_path}', \"\n",
    "            f\"substituted is '{substituted_path}'). \"\n",
    "            f\"Using the same projected image as was used during registration.\"\n",
    "        )\n",
    "\n",
    "    #####################\n",
    "    ### Load the file ###\n",
    "    #####################\n",
    "    array = load_image(settings.histology_path, allow_stack=True)\n",
    "\n",
    "    if len(array.shape) not in [2, 3]:\n",
    "        _module_logger.error(\n",
    "            \"Only image arrays with 2 and 3 dimensions (XY and XYZ) are allowed.\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    #####################################\n",
    "    ### Compute the origin and normal ###\n",
    "    #####################################\n",
    "    alignment_origin = compute_origin(\n",
    "        compute_centre(settings.volume_settings.shape), settings.volume_settings\n",
    "    )\n",
    "    alignment_normal = compute_normal(settings.volume_settings)\n",
    "\n",
    "    ############################\n",
    "    ### Check dimensionality ###\n",
    "    ############################\n",
    "    # List all the 2D images along their origins\n",
    "    images = []\n",
    "    origins = []\n",
    "    # If 2D, only one image and origin\n",
    "    if len(array.shape) == 2:\n",
    "        images = [array]\n",
    "        origins = [alignment_origin]\n",
    "    # If 3D, separate each image and compute its origin\n",
    "    else:\n",
    "        slice_ = [slice(None)] * len(array.shape)\n",
    "        # Assume the Z-dimension is the smallest one\n",
    "        z_dimension_index = array.shape.index(min(array.shape))\n",
    "        z_count = array.shape[z_dimension_index]\n",
    "\n",
    "        # Loop over each Z-slice to extract the images\n",
    "        for index in range(z_count):\n",
    "            slice_[z_dimension_index] = index\n",
    "            images.append(array[tuple(slice_)])\n",
    "\n",
    "        # Loop over multiple of the normal to get origins\n",
    "        for i in range(-int(z_count / 2) + (z_count % 2 == 0), z_count // 2 + 1):\n",
    "            # TODO: Scale multiple by the real Z-spacing (currently assuming same as\n",
    "            #       resolution.\n",
    "            origins.append(alignment_origin + i * alignment_normal)\n",
    "\n",
    "    ###########################\n",
    "    ### Register each image ###\n",
    "    ###########################\n",
    "    registrator = Registrator()\n",
    "    for index, origin in enumerate(origins):\n",
    "        image = registrator.get_forwarded_image(\n",
    "            images[index], settings, origin.tolist()\n",
    "        )\n",
    "        images[index] = image\n",
    "\n",
    "    #############################\n",
    "    ### Generate point clouds ###\n",
    "    #############################\n",
    "    # Loop over each image and generate its 3D point cloud\n",
    "    point_clouds = []\n",
    "    no_rotation_normal = compute_normal_from_raw(\n",
    "        0, 0, settings.volume_settings.orientation\n",
    "    )\n",
    "    for image, origin in zip(images, origins):\n",
    "        # Build a plane assuming no rotations\n",
    "        plane = vedo.Plane(pos=(0, 0, 0), normal=no_rotation_normal, s=image.shape)\n",
    "\n",
    "        # Extract the four corners of the plane\n",
    "        p0, p1, _, p3 = plane.points\n",
    "\n",
    "        # Compute the normals of two orthogonal edges\n",
    "        normal1 = (p0 - p1) / euclidean(p1, p0)\n",
    "        normal2 = (p3 - p1) / euclidean(p1, p3)\n",
    "\n",
    "        # Apply alignment rotation on normals\n",
    "        normal1 = apply_rotation(normal1, settings.volume_settings)\n",
    "        normal2 = apply_rotation(normal2, settings.volume_settings)\n",
    "\n",
    "        # Generate a grid of coordinates the same size as the plane\n",
    "        xs, ys = np.meshgrid(\n",
    "            np.linspace(0, round(euclidean(p1, p0)), round(euclidean(p1, p0))),\n",
    "            np.linspace(0, round(euclidean(p1, p3)), round(euclidean(p1, p3))),\n",
    "        )\n",
    "        points = np.vstack([xs.ravel(), ys.ravel()])\n",
    "\n",
    "        # Apply alignment rotation on the points\n",
    "        points = np.dot(np.vstack((normal1, normal2)).T, points).T\n",
    "\n",
    "        # Convert points to a vedo Points object to compute the centre of mass\n",
    "        points_vedo = vedo.Points(points)\n",
    "\n",
    "        # Translate the grid origin to the alignment origin\n",
    "        points += -points_vedo.center_of_mass() + origin\n",
    "        points_vedo = vedo.Points(points)\n",
    "\n",
    "        # Insert point data from registered image\n",
    "        points_vedo.pointdata[\"ImageScalars\"] = image.flatten()\n",
    "\n",
    "        point_clouds.append(points_vedo)\n",
    "\n",
    "    # Interpolate the point clouds\n",
    "    if alignment_array is None:\n",
    "        alignment_array = np.zeros(settings.volume_settings.shape, dtype=np.uint16)\n",
    "        query_volume = vedo.Volume(alignment_array)\n",
    "\n",
    "    for points in point_clouds:\n",
    "        # Interpolate and store the result in a temporary array\n",
    "        tmp_array = query_volume.interpolate_data_from(points, radius=1).tonumpy()\n",
    "        tmp_array = np.round(tmp_array).astype(np.uint16)\n",
    "\n",
    "        # TODO: Might be worth thinking of another way to merge. Using the maximum works\n",
    "        #       fine when working with non-overlapping slices but a mean or something\n",
    "        #       more robust might make more sense when tmp_array and aligned_array have\n",
    "        #       common, non-zero points.\n",
    "        # Merge the new plane into the master array\n",
    "        alignment_array[:] = np.maximum(alignment_array, tmp_array)\n",
    "\n",
    "alignment_volume = vedo.Volume(alignment_array)"
   ],
   "id": "4d06a7d620fdeb21"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Validate arguments\n",
    "if channel_regex is not None and channel_index is None:\n",
    "    _module_logger.warning(\n",
    "        \"Received channel regex but no channel index. Building alignment \"\n",
    "        \"volume using the same channel as was used for alignment.\"\n",
    "    )\n",
    "elif channel_regex is None and channel_index is not None:\n",
    "    _module_logger.warning(\n",
    "        \"Received channel index but no channel regex. Building alignment \"\n",
    "        \"volume using the same channel as was used for alignment.\"\n",
    "    )\n",
    "\n",
    "_module_logger.debug(\n",
    "    f\"Building alignment volume for directory '{alignment_directory}'.\"\n",
    ")\n",
    "\n",
    "# Gather all the alignment settings paths\n",
    "alignment_paths = gather_alignment_paths(alignment_directory)\n",
    "if not alignment_paths:\n",
    "    _module_logger.error(f\"No alignments found for directory '{alignment_directory}'.\")\n",
    "    return\n",
    "\n",
    "_module_logger.debug(f\"Found {len(alignment_paths)} alignments.\")\n",
    "\n",
    "# Inspect cache\n",
    "# TODO: Improve cache path so that it takes into account regexes\n",
    "cache_directory = alignment_directory / \"volumes\" / \"aligned\"\n",
    "os.makedirs(cache_directory, exist_ok=True)\n",
    "cache_path = cache_directory / f\"{alignment_directory.name}.h5\"\n",
    "if cache_path.exists() and not force:\n",
    "    return\n",
    "# Array inside which to store interpolated data from alignment point clouds\n",
    "alignment_array = None\n",
    "# Dummy volume used to query the grid coordinates when interpolating\n",
    "query_volume = None\n",
    "for progress_index, alignment_path in enumerate(alignment_paths):\n",
    "    if (progress := progress_index + 1) % 5 == 0:\n",
    "        _module_logger.debug(\n",
    "            f\"Gathered {progress}/{len(alignment_paths)} slices ({progress / len(alignment_paths):.0%}).\"\n",
    "        )\n",
    "\n",
    "    # Load the alignment settings\n",
    "    settings = AlignmentSettings(**json.load(alignment_path.open()))\n",
    "\n",
    "    # Apply regex substitution to the histology path\n",
    "    substituted_path = replace_path_parts(\n",
    "        settings.histology_path,\n",
    "        channel_index,\n",
    "        channel_regex,\n",
    "        projection_regex,\n",
    "        misc_regexes,\n",
    "        misc_subs,\n",
    "    )\n",
    "    try:\n",
    "        settings.histology_path = substituted_path\n",
    "    except pydantic.ValidationError:\n",
    "        _module_logger.warning(\n",
    "            f\"Histology path after regex substitution does not exist for \"\n",
    "            f\"'{settings.histology_path}' (substituted: '{substituted_path}'). \"\n",
    "            f\"Using the same projected image as was used during registration.\"\n",
    "        )\n",
    "\n",
    "    # Load the image array (allowed to be 2D or 3D)\n",
    "    array = load_image(settings.histology_path, allow_stack=True)\n",
    "    if len(array.shape) not in [2, 3]:\n",
    "        _module_logger.error(\n",
    "            \"Only image arrays with 2 and 3 dimensions (XY and XYZ) are allowed.\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    # Compute the origin and normal as described by the alignment\n",
    "    alignment_origin = compute_origin(\n",
    "        compute_centre(settings.volume_settings.shape), settings.volume_settings\n",
    "    )\n",
    "    alignment_normal = compute_normal(settings.volume_settings)\n",
    "\n",
    "    # List all the 2D images along their origins\n",
    "    images = []\n",
    "    origins = []\n",
    "    # If 2D, only one image and origin\n",
    "    if len(array.shape) == 2:\n",
    "        images = [array]\n",
    "        origins = [alignment_origin]\n",
    "    # If 3D, extract each image and compute its origin\n",
    "    else:\n",
    "        slice_ = [slice(None)] * len(array.shape)\n",
    "        # Assume the Z-dimension is the smallest one\n",
    "        z_dimension_index = array.shape.index(min(array.shape))\n",
    "        z_count = array.shape[z_dimension_index]\n",
    "\n",
    "        # Loop over each Z-slice to extract the images\n",
    "        for index in range(z_count):\n",
    "            slice_[z_dimension_index] = index\n",
    "            images.append(array[tuple(slice_)])\n",
    "\n",
    "        # Loop over multiple of the normal to get origins\n",
    "        for i in range(-int(z_count / 2) + (z_count % 2 == 0), z_count // 2 + 1):\n",
    "            # TODO: Scale multiple by the real Z-spacing (currently assuming same as\n",
    "            #       resolution).\n",
    "            origins.append(alignment_origin + i * alignment_normal)\n",
    "\n",
    "    # Register each image\n",
    "    registrator = Registrator()\n",
    "    for index, origin in enumerate(origins):\n",
    "        image = registrator.get_forwarded_image(\n",
    "            images[index], settings, origin.tolist()\n",
    "        )\n",
    "        images[index] = image\n",
    "\n",
    "    # Loop over each image and generate its 3D point cloud\n",
    "    point_clouds = []\n",
    "    for image, origin in zip(images, origins):\n",
    "        cloud = build_point_cloud(origin, image.shape, settings.volume_settings)\n",
    "\n",
    "        # Insert point data from registered image\n",
    "        cloud.pointdata[\"ImageScalars\"] = image.flatten()\n",
    "\n",
    "        point_clouds.append(cloud)\n",
    "\n",
    "    # Interpolate the point clouds\n",
    "    if alignment_array is None:\n",
    "        alignment_array = np.zeros(settings.volume_settings.shape, dtype=np.uint16)\n",
    "        query_volume = vedo.Volume(alignment_array)\n",
    "\n",
    "    for points in point_clouds:\n",
    "        # Interpolate and store the result in a temporary array\n",
    "        tmp_array = query_volume.interpolate_data_from(points, radius=1).tonumpy()\n",
    "        # tmp_array = query_volume.resample_data_from(points).tonumpy()\n",
    "        tmp_array = np.round(tmp_array).astype(np.uint16)\n",
    "\n",
    "        # TODO: Might be worth thinking of another way to merge. Using the maximum works\n",
    "        #       fine when working with non-overlapping slices but a mean or something\n",
    "        #       more robust might make more sense when tmp_array and\n",
    "        #       interpolation_array have common, non-zero points.\n",
    "        # Merge the new plane into the master array\n",
    "        alignment_array[:] = np.maximum(alignment_array, tmp_array)\n",
    "\n",
    "_module_logger.debug(f\"Finished gathering slices. Caching result to '{cache_path}'.\")\n",
    "with h5py.File(cache_path, \"w\") as handle:\n",
    "    handle.create_dataset(name=\"array\", data=alignment_array, compression=\"gzip\")\n",
    "append_volume(alignment_directory, cache_path, \"aligned\")"
   ],
   "id": "647ed863142df6df"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
