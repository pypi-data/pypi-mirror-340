{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import hashlib\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import random\n",
    "from time import perf_counter\n",
    "from typing import Optional\n",
    "\n",
    "import cv2\n",
    "import h5py\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import filters, restoration\n",
    "import tifffile\n",
    "\n",
    "from histalign.backend.ccf.downloads import (\n",
    "    download_annotation_volume,\n",
    "    download_structure_mask,\n",
    ")\n",
    "from histalign.backend.ccf.paths import get_annotation_path, get_structure_mask_path\n",
    "from histalign.backend.io import load_volume\n",
    "from histalign.backend.models import Resolution"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T17:31:44.623528Z",
     "start_time": "2025-03-12T17:31:44.540327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def imshow(\n",
    "    image: np.ndarray,\n",
    "    title: str | None = None,\n",
    "    figsize: tuple[int, int] | None = None,\n",
    "    cmap: str | None = \"gray\",\n",
    ") -> None:\n",
    "    global _distinct_colours\n",
    "\n",
    "    _ = plt.figure(figsize=figsize)\n",
    "\n",
    "    if title is not None:\n",
    "        plt.suptitle(title)\n",
    "    plt.axis(False)\n",
    "\n",
    "    if cmap == \"distinct\":\n",
    "        cmap = generate_distinct_cmap(image)\n",
    "\n",
    "    plt.imshow(image, cmap=cmap)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_annotation_contours(image: np.ndarray) -> list[list[np.ndarray]]:\n",
    "    contours = []\n",
    "    for value in np.unique(image):\n",
    "        contours.append(\n",
    "            cv2.findContours(\n",
    "                (image == value).astype(np.uint8), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE\n",
    "            )[0]\n",
    "        )\n",
    "\n",
    "    return contours\n",
    "\n",
    "\n",
    "def get_structures_contours(\n",
    "    structures: list[str],\n",
    "    index: tuple[int, int, int],\n",
    "    resolution: Resolution.MICRONS_100,\n",
    ") -> list[np.ndarray]:\n",
    "    index = tuple(slice(None) if value == -1 else value for value in index)\n",
    "\n",
    "    contours = []\n",
    "    for structure in structures:\n",
    "        volume_path = get_structure_mask_path(structure, resolution)\n",
    "        if not os.path.exists(volume_path):\n",
    "            download_structure_mask(structure, resolution)\n",
    "\n",
    "        volume = load_volume(volume_path, return_raw_array=True)\n",
    "\n",
    "        image = volume[index]\n",
    "        contours += cv2.findContours(\n",
    "            (image > 0).astype(np.uint8), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE\n",
    "        )[0]\n",
    "\n",
    "    return contours\n",
    "\n",
    "\n",
    "def draw_contours(image: np.ndarray, contours: list[np.ndarray]) -> np.ndarray:\n",
    "    cv2.drawContours(image, contours, -1, (255, 255, 255))\n",
    "\n",
    "\n",
    "def save_contours(contours: list[np.ndarray], file_path: str | Path) -> None:\n",
    "    masked_array = None\n",
    "    largest_shape = max(map(lambda x: x.shape, contours), key=lambda x: x[0])\n",
    "\n",
    "    for contour in contours:\n",
    "        resized_array = contour.astype(np.uint16)\n",
    "        resized_array.resize(largest_shape)\n",
    "\n",
    "        mask = np.ones(contour.shape, dtype=bool)\n",
    "        mask.resize(largest_shape)\n",
    "        mask = ~mask\n",
    "\n",
    "        new_masked_array = np.ma.array(resized_array, mask=mask)[np.newaxis]\n",
    "\n",
    "        if masked_array is None:\n",
    "            masked_array = new_masked_array\n",
    "        else:\n",
    "            masked_array = np.ma.concatenate([masked_array, new_masked_array], axis=0)\n",
    "\n",
    "    np.savez_compressed(file_path, data=masked_array.data, mask=masked_array.mask)\n",
    "\n",
    "\n",
    "def load_masked_array(file_path: str | Path) -> np.ma.MaskedArray:\n",
    "    with np.load(file_path) as handle:\n",
    "        data = handle[\"data\"].astype(np.int32)\n",
    "        mask = handle[\"mask\"]\n",
    "\n",
    "    return np.ma.array(data, mask=mask)\n",
    "\n",
    "\n",
    "def load_contours(file_path: str | Path) -> list[np.ndarray]:\n",
    "    masked_array = load_masked_array(file_path)\n",
    "\n",
    "    return [\n",
    "        masked_array[i][~masked_array.mask[i]].data.reshape(-1, 1, 2)\n",
    "        for i in range(masked_array.shape[0])\n",
    "    ]\n",
    "\n",
    "\n",
    "def chaikins_corner_cutting(coords: np.ndarray, refinements: int = 5):\n",
    "    coords = np.array(coords)\n",
    "\n",
    "    for _ in range(refinements):\n",
    "        L = coords.repeat(2, axis=0)\n",
    "        R = np.empty_like(L)\n",
    "        R[0] = L[0]\n",
    "        R[2::2] = L[1:-1:2]\n",
    "        R[1:-1:2] = L[2::2]\n",
    "        R[-1] = L[-1]\n",
    "        coords = L * 0.75 + R * 0.25\n",
    "\n",
    "    return coords"
   ],
   "id": "85a64700b32a7c53",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "CONTOUR_CACHE_PATH = Path(\"contour_cache.pkl\")\n",
    "CONTOUR_CACHE_MAP_PATH = Path(\"contour_cache_map.json\")\n",
    "\n",
    "Contour = np.ndarray\n",
    "\n",
    "\n",
    "class ContourCache:\n",
    "    auto_save: bool\n",
    "    max_contours: int\n",
    "    max_points: int\n",
    "\n",
    "    _contours: list[list[Contour]]\n",
    "    _count: int\n",
    "    _key_contours_dict: dict[str, int]\n",
    "\n",
    "    def __init__(\n",
    "        self, auto_save: bool = True, max_contours: int = 2_000, max_points: int = 5_000\n",
    "    ) -> None:\n",
    "        \"\"\"A cache object granting access to the local contour cache.\n",
    "\n",
    "        The default sizes should result in at most a 20MB file on disk for the contours\n",
    "        (and another smaller one for the dictionary) and around twice that when loaded\n",
    "        in memory. This doubling is due to the fact that OpenCV needs contours as int32\n",
    "        but we store them as uint16.\n",
    "\n",
    "        Args:\n",
    "            auto_save (bool, optional):\n",
    "                Whether the case should save after every additional and removal.\n",
    "            max_contours (int, optional):\n",
    "                How many contours the cache should hold at any one point. This is an\n",
    "                upper limit and might never be 100% utilised.\n",
    "            max_points (int, optional):\n",
    "                How many points any one contour is allowed to have.\n",
    "        \"\"\"\n",
    "        self.auto_save = auto_save\n",
    "        self.max_contours = max_contours\n",
    "        self.max_points = max_points\n",
    "\n",
    "        self._contours = []\n",
    "        self._count = 0\n",
    "        self._key_contours_dict = {}\n",
    "\n",
    "    @property\n",
    "    def entries(self) -> list[str]:\n",
    "        return list(self._key_contours_dict.keys())\n",
    "\n",
    "    def has_contours(self, key: str) -> bool:\n",
    "        \"\"\"Returns whether the given key is associated with cached contours.\n",
    "\n",
    "        Note that providing a key, even obtained from an add operation, is not\n",
    "        guaranteed to return `True`. If the cache grew and dropped the contours\n",
    "        associated with this key, the function will return `False`.\n",
    "\n",
    "        Args:\n",
    "            key (str): Key to retrieve the contours with.\n",
    "\n",
    "        Returns:\n",
    "            bool: Whether the key is associated with cached contours.\n",
    "        \"\"\"\n",
    "        return key in self._key_contours_dict.keys()\n",
    "\n",
    "    def insert_contours(\n",
    "        self,\n",
    "        contours: list[Contour],\n",
    "        key: str = \"\",\n",
    "    ) -> str:\n",
    "        \"\"\"Adds contours to the cache.\n",
    "\n",
    "        Args:\n",
    "            contours (list[Contour]): Contours to cache.\n",
    "            key (str, optional):\n",
    "                Optional key to assign to the contours. If omitted, it is automatically\n",
    "                generated.\n",
    "\n",
    "        Returns:\n",
    "            str:\n",
    "                The key associated with the contours. This can be used to retrieve the\n",
    "                contours if they are still in the case.\n",
    "\n",
    "        Raises:\n",
    "            ValueError:\n",
    "                When attempting to add contours with more points than allowed or when\n",
    "                attempting to add more contours than the cache can store.\n",
    "        \"\"\"\n",
    "        max_points = max(map(lambda x: x.shape[0], contours))\n",
    "        if max_points > self.max_points:\n",
    "            raise ValueError(\n",
    "                f\"Tried adding a contour with more points than allowed \"\n",
    "                f\"({max_points} > {self.max_points}).\"\n",
    "            )\n",
    "\n",
    "        contour_count = len(contours)\n",
    "        if contour_count > self.max_contours:\n",
    "            raise ValueError(\n",
    "                f\"Tried adding more contours in one go than the cache allows \"\n",
    "                f\"({contour_count} > {self.max_contours}).\"\n",
    "            )\n",
    "\n",
    "        key = key or self.generate_key(contours)\n",
    "        exists = self.has_contours(key)\n",
    "\n",
    "        # Ensure we don't go over the contour limit\n",
    "        total_count = self._count + contour_count\n",
    "        if exists:\n",
    "            total_count -= len(self._contours[self._key_contours_dict[key]])\n",
    "\n",
    "        if total_count > self.max_contours:\n",
    "            removed_count = self._invalidate_contours(total_count - self.max_contours)\n",
    "            total_count -= removed_count\n",
    "\n",
    "        if exists:\n",
    "            self._contours[self._key_contours_dict[key]] = contours\n",
    "        else:\n",
    "            self._contours.append(contours)\n",
    "            self._key_contours_dict[key] = len(self._contours) - 1\n",
    "\n",
    "        self._count = total_count\n",
    "\n",
    "        if self.auto_save:\n",
    "            self.save()\n",
    "\n",
    "        return key\n",
    "\n",
    "    def load_contours(self, key: str, allow_missing: bool = False) -> list[Contour]:\n",
    "        \"\"\"Retrieves the contours associated with the given key.\n",
    "\n",
    "        Args:\n",
    "            key (str): Key used to retrieve the contours.\n",
    "            allow_missing (bool, optional):\n",
    "                Whether to error out when the key is not associated with any contours.\n",
    "\n",
    "        Returns:\n",
    "            list[Contour]:\n",
    "                A list containing the retrieved contours or an empty list if no contours\n",
    "                exist and `allow_missing` is `True`.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: When the cache misses and `allow_missing` is `False`.\n",
    "        \"\"\"\n",
    "        if not self.has_contours(key):\n",
    "            if allow_missing:\n",
    "                return []\n",
    "            raise ValueError(f\"No cached contours for the given key '{key}'.\")\n",
    "\n",
    "        return self._contours[self._key_contours_dict[key]]\n",
    "\n",
    "    def pop_contours(\n",
    "        self, key: str, allow_missing: bool = False, decrement_indices: bool = True\n",
    "    ) -> list[Contour]:\n",
    "        \"\"\"Pops the contours associated with the given key from the cache.\n",
    "\n",
    "        Args:\n",
    "            key (str): Key used to retrieve the contours.\n",
    "            allow_missing (bool, optional):\n",
    "                Whether to error out when the key is not associated with any contours.\n",
    "            decrement_indices (bool, optional):\n",
    "                Whether to decrement other indices on removal.\n",
    "\n",
    "        Returns:\n",
    "            list[Contour]:\n",
    "                The removed contours or an empty list if not contours exist and\n",
    "                `allow_missing` is `True`.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: When the cache misses and `allow_missing` is `False`.\n",
    "        \"\"\"\n",
    "        if not self.has_contours(key):\n",
    "            if allow_missing:\n",
    "                return []\n",
    "            raise ValueError(f\"No cached contours for the given key '{key}'.\")\n",
    "\n",
    "        index = self._key_contours_dict.pop(key)\n",
    "        contours = self._contours.pop(index)\n",
    "\n",
    "        self._count -= len(contours)\n",
    "        if decrement_indices:\n",
    "            self._decrement_indices(index)\n",
    "\n",
    "        if self.auto_save:\n",
    "            self.save()\n",
    "\n",
    "        return contours\n",
    "\n",
    "    # noinspection PyTypeChecker\n",
    "    def save(self) -> None:\n",
    "        \"\"\"Saves the cache to disk.\"\"\"\n",
    "        with open(CONTOUR_CACHE_PATH, \"wb\") as handle:\n",
    "            pickle.dump(self._contours, handle)\n",
    "\n",
    "        with open(CONTOUR_CACHE_MAP_PATH, \"wb\") as handle:\n",
    "            pickle.dump(self._key_contours_dict, handle)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls) -> ContourCache:\n",
    "        \"\"\"Loads and returns the contour cache.\n",
    "\n",
    "        Returns:\n",
    "            ContourCache: The contour cache.\n",
    "        \"\"\"\n",
    "        instance = cls()\n",
    "\n",
    "        if CONTOUR_CACHE_PATH.exists():\n",
    "            with open(CONTOUR_CACHE_PATH, \"rb\") as handle:\n",
    "                instance._contours = pickle.load(handle)\n",
    "\n",
    "            if CONTOUR_CACHE_MAP_PATH.exists():\n",
    "                with open(CONTOUR_CACHE_MAP_PATH, \"rb\") as handle:\n",
    "                    instance._key_contours_dict = pickle.load(handle)\n",
    "\n",
    "            instance._count = sum(map(lambda x: len(x), instance._contours))\n",
    "\n",
    "        return instance\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_key(contours: list[Contour]) -> str:\n",
    "        \"\"\"Generates a key for the provided contours.\n",
    "\n",
    "        Returns:\n",
    "            str: The key generated from the contours.\n",
    "        \"\"\"\n",
    "        keys = [hashlib.md5(contour.tobytes()).hexdigest() for contour in contours]\n",
    "\n",
    "        return hashlib.md5(\"\".join(keys).encode(\"UTF-8\")).hexdigest()\n",
    "\n",
    "    def _decrement_indices(self, start_index: int) -> None:\n",
    "        \"\"\"Decrements all indices after `start_index`.\n",
    "\n",
    "        Args:\n",
    "            start_index (int):\n",
    "        \"\"\"\n",
    "        for key, index in self._key_contours_dict.items():\n",
    "            if index > start_index:\n",
    "                self._key_contours_dict[key] = index - 1\n",
    "\n",
    "    def _invalidate_contours(self, count: int) -> int:\n",
    "        \"\"\"Removes at least `count` contours from the cache.\n",
    "\n",
    "        Returns:\n",
    "            int: How many contours were removed.\n",
    "        \"\"\"\n",
    "        i = 0\n",
    "        removed = 0\n",
    "        while removed < count:\n",
    "            i += 1\n",
    "            oldest_key = min(self._key_contours_dict.items(), key=lambda x: x[1])[0]\n",
    "\n",
    "            contours = self.pop_contours(oldest_key, decrement_indices=False)\n",
    "            removed += len(contours)\n",
    "\n",
    "        self._decrement_indices(i)\n",
    "\n",
    "        return removed"
   ],
   "id": "c40d3aaac5f5974e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "resolution = Resolution.MICRONS_25\n",
    "shape = (528, 320, 456)\n",
    "index = (-1, 50, -1)\n",
    "\n",
    "with open(\"ccf_annotations_expanded.csv\") as handle:\n",
    "    contents = handle.read()\n",
    "\n",
    "lines = contents.split(\"\\n\")[1:]\n",
    "structures = list(map(lambda x: x.split(\",\")[2].strip(), lines))\n",
    "\n",
    "structures.remove(\"Primary somatosensory area upper limb\")\n",
    "structures.remove(\"Retrosplenial area lateral agranular part\")\n",
    "structures.remove(\"Retrosplenial area dorsal part\")\n",
    "structures.remove(\"Retrosplenial area ventral part\")\n",
    "structures.remove(\"Primary somatosensory area barrel field\")\n",
    "structures.remove(\"Primary somatosensory area lower limb\")\n",
    "structures.remove(\"Primary somatosensory area mouth\")\n",
    "structures.remove(\"Primary somatosensory area nose\")\n",
    "structures.remove(\"Primary somatosensory area trunk\")\n",
    "structures.remove(\"Primary somatosensory area upper limb\")\n",
    "structures.remove(\"Primary somatosensory area unassigned\")\n",
    "structures.remove(\"Posteromedial visual area\")\n",
    "structures.remove(\"Anterior visual area\")\n",
    "structures.remove(\"Laterointermediate visual area\")\n",
    "structures.remove(\"Rostrolateral area\")\n",
    "\n",
    "structures += [\n",
    "    \"Primary somatosensory area, upper limb\",\n",
    "    \"Retrosplenial area, lateral agranular part\",\n",
    "    \"Retrosplenial area, dorsal part\",\n",
    "    \"Retrosplenial area, ventral part\",\n",
    "    \"Primary somatosensory area, barrel field\",\n",
    "    \"Primary somatosensory area, lower limb\",\n",
    "    \"Primary somatosensory area, mouth\",\n",
    "    \"Primary somatosensory area, nose\",\n",
    "    \"Primary somatosensory area, trunk\",\n",
    "    \"Primary somatosensory area, upper limb\",\n",
    "    \"Primary somatosensory area, unassigned\",\n",
    "    \"posteromedial visual area\",\n",
    "    # \"Anterior visual area\",\n",
    "    # \"Laterointermediate visual area\",\n",
    "    # \"Rostrolateral area\",\n",
    "]\n",
    "\n",
    "cache = ContourCache.load()\n",
    "cache.auto_save = False"
   ],
   "id": "63c2ea06f98fb744",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for structure in structures:\n",
    "    key = str([resolution.value, index, structure])\n",
    "    if cache.has_contours(key):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        contours = get_structures_contours([structure], index, resolution)\n",
    "    except KeyError:\n",
    "        print(f\"Unknown structure: {structure}\")\n",
    "        continue\n",
    "\n",
    "    if len(contours) < 1:\n",
    "        continue\n",
    "\n",
    "    cache.insert_contours(contours, key)\n",
    "\n",
    "cache.save()"
   ],
   "id": "d9f8eecdce861080",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_contours = []\n",
    "for structure in structures:\n",
    "    key = str([resolution.value, index, structure])\n",
    "    all_contours += cache.load_contours(key, allow_missing=True)"
   ],
   "id": "84e3e923252afef9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "overlay = np.zeros(\n",
    "    np.array(shape)[np.where(np.array(index) == -1)[0]].T, dtype=np.uint8\n",
    ")\n",
    "draw_contours(overlay, all_contours)\n",
    "\n",
    "imshow(overlay, figsize=(20, 20))"
   ],
   "id": "7de15e1b221fb922",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
