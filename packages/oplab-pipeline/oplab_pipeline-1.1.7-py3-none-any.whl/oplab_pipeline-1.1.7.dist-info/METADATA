Metadata-Version: 2.4
Name: oplab_pipeline
Version: 1.1.7
Summary: Toolchain for AUV dive processing, camera calibration and image correction
Home-page: https://github.com/ocean-perception/oplab_pipeline
Author: Ocean Perception - University of Southampton
Author-email: miquel.massot-campos@soton.ac.uk
License: BSD
Classifier: Development Status :: 2 - Pre-Alpha
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: BSD License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Scientific/Engineering
Classifier: Topic :: Software Development
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: argcomplete>=1.12.3
Requires-Dist: argparse>=1.1
Requires-Dist: colour_demosaicing>=0.1.5
Requires-Dist: geographiclib>=1.50
Requires-Dist: imageio>=2.6.1
Requires-Dist: joblib>=0.14.1
Requires-Dist: matplotlib>=3.2.1
Requires-Dist: numba>=0.56.4
Requires-Dist: numpy>=1.23.0
Requires-Dist: opencv-python-headless>=4.1.2
Requires-Dist: pandas>=0.25.3
Requires-Dist: pillow>=7.2.0
Requires-Dist: plotly>=4.7.1
Requires-Dist: plyfile>=0.7.2
Requires-Dist: prettytable>=3.5.0
Requires-Dist: psutil>=5.8.0
Requires-Dist: pynmea2>=1.15.0
Requires-Dist: pytz>=2019.3
Requires-Dist: PyYAML>=3.12
Requires-Dist: scikit_image>=0.17
Requires-Dist: scipy>=1.4.1
Requires-Dist: tqdm>=4.64.0
Requires-Dist: wheel>=0.30.0
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: license
Dynamic: license-file
Dynamic: requires-dist
Dynamic: summary

[![oplab_pipeline](https://github.com/ocean-perception/oplab_pipeline/actions/workflows/oplab_pipeline.yml/badge.svg)](https://github.com/ocean-perception/oplab_pipeline/actions/workflows/oplab_pipeline.yml) [![CC BY-NC-SA 4.0][cc-by-nc-sa-shield]][cc-by-nc-sa] [![Code Coverage](https://codecov.io/gh/ocean-perception/oplab_pipeline/branch/master/graph/badge.svg?token=PJBfl6qhp5)](https://codecov.io/gh/ocean-perception/oplab_pipeline) [![Documentation Status](https://readthedocs.org/projects/oplab-pipeline/badge/?version=latest)](https://oplab-pipeline.readthedocs.io/en/latest/?badge=latest) [![Docker Image CI](https://github.com/ocean-perception/oplab_pipeline/actions/workflows/docker_image.yml/badge.svg)](https://github.com/ocean-perception/oplab_pipeline/actions/workflows/docker_image.yml) [![DOI](https://zenodo.org/badge/101513536.svg)](https://zenodo.org/badge/latestdoi/101513536)



# oplab_pipeline

oplab_pipeline is a python toolchain to process AUV dives from raw data into navigation and imaging products. The software is capable of:

- Process navigation: fuses AUV or ROV sensor data using state of the art filters and geolocalises recorded imagery.
- Camera and laser calibration: performs automatic calibration pattern detection to calibrate monocular or stereo cameras. Also calibrates laser sheets with respect to the cameras.
- Image correction: performs pixel-wise image corrections to enhance colour and contrast in underwater images.

Please review the latest changes in the [CHANGELOG.md](CHANGELOG.md). 


## Installation

For __production__, to install this package run:
```bash
pip install -U git+https://github.com/ocean-perception/oplab_pipeline.git
```

This will make the commands `auv_nav`, `auv_cal` and `correct_images` available in the terminal. For more details refer to the documentation.

For __development__, clone the repository, navigate to the oplab-pipeline folder and run 
```bash
pip install -U --user -e .
```

Notes:

To import rosbag, using `pip install baypy`. (see the docs: https://jmscslgroup.github.io/bagpy/)

## Documentation
The documentation is hosted in [read the docs](https://oplab-pipeline.readthedocs.io).


## Citation
If you use this software, please cite the following article:

> Yamada, T, Prügel‐Bennett, A, Thornton, B. Learning features from georeferenced seafloor imagery with location guided autoencoders. J Field Robotics. 2020; 1– 16. https://doi.org/10.1002/rob.21961


## License
Copyright (c) 2020-2022, University of Southampton. All rights reserved.
This work is licensed under a
[Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License][cc-by-nc-sa].

See LICENSE.md file in the project root for full license information.

## Contributing
Please document the code using [Numpy Docstrings](https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_numpy.html).
If you are using VSCode, there is a useful extension that helps named [Python Docstring Generator](https://marketplace.visualstudio.com/items?itemName=njpwerner.autodocstring). Once installed, make sure you select Numpy documentation in the settings.

Run `pre-commit install` to install [pre-commit](https://pre-commit.com/) into your git hooks. pre-commit will now run on every commit. If you don't have `pre-commit` installed, run `pip install pre-commit`.


[cc-by-nc-sa]: http://creativecommons.org/licenses/by-nc-sa/4.0/
[cc-by-nc-sa-image]: https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png
[cc-by-nc-sa-shield]: https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg
