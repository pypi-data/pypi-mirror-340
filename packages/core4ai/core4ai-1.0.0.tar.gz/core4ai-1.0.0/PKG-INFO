Metadata-Version: 2.4
Name: core4ai
Version: 1.0.0
Summary: Contextual Optimization and Refinement Engine for AI
Author-email: Rahul Pandey <rpandey1901@gmail.com>
License: Apache-2.0
Project-URL: Homepage, https://github.com/iRahulPandey/core4ai
Project-URL: Bug Tracker, https://github.com/iRahulPandey/core4ai/issues
Project-URL: Documentation, https://github.com/iRahulPandey/core4ai#readme
Project-URL: Source Code, https://github.com/iRahulPandey/core4ai
Keywords: llm,prompt,mlflow,ai,ollama,openai,template
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Operating System :: OS Independent
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Developers
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: click>=8.0.0
Requires-Dist: mcp[cli]>=0.0.29
Requires-Dist: langchain>=0.1.0
Requires-Dist: langchain-mcp-adapters>=0.0.5
Requires-Dist: langchain-openai>=0.0.5
Requires-Dist: langgraph>=0.0.20
Requires-Dist: mlflow>=2.21.0
Requires-Dist: python-dotenv
Requires-Dist: pyyaml
Requires-Dist: requests
Requires-Dist: aiohttp
Requires-Dist: rich>=10.0.0
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.21.0; extra == "dev"
Requires-Dist: pytest-cov>=4.1.0; extra == "dev"
Dynamic: license-file

# Core4AI: Contextual Optimization and Refinement Engine for AI

Core4AI is an intelligent system that transforms basic user queries into optimized prompts for AI systems using MLflow Prompt Registry. It dynamically matches user requests to the most appropriate prompt template and applies it with extracted parameters.

## âœ¨ Key Features

- **ğŸ“š Centralized Prompt Management**: Store, version, and track prompts in MLflow
- **ğŸ§  Intelligent Prompt Matching**: Automatically match user queries to optimal templates
- **ğŸ”„ Dynamic Parameter Extraction**: Identify and extract parameters from natural language
- **ğŸ” Content Type Detection**: Recognize the type of content being requested
- **ğŸ› ï¸ Multiple AI Providers**: Seamless integration with OpenAI and Ollama
- **ğŸ“Š Detailed Response Tracing**: Track prompt optimization and transformation stages
- **ğŸ“ Version Control**: Track prompt history with production and archive aliases
- **ğŸ§© Extensible Framework**: Add new prompt types without code changes

## ğŸš€ Installation

### Basic Installation

```bash
# Install from PyPI
pip install core4ai
```

### Development Installation

```bash
# Clone the repository
git clone https://github.com/iRahulPandey/core4ai.git
cd core4ai

# Install in development mode
pip install -e ".[dev]"
```

## âš™ï¸ Initial Configuration

After installation, run the interactive setup wizard:

```bash
# Run the setup wizard
core4ai setup
```

The wizard will guide you through:

1. **MLflow Configuration**: 
   - Enter the URI of your MLflow server (default: http://localhost:8080)
   - Core4AI will use MLflow to store and version your prompts

2. **AI Provider Selection**:
   - Choose between OpenAI or Ollama
   - For OpenAI: Set your API key as an environment variable:
     ```bash
     export OPENAI_API_KEY="your-api-key-here"
     ```
   - For Ollama: Specify the server URI and model to use

## ğŸ› ï¸ Usage Examples

### Managing Prompts

```bash
# Register a new prompt with a template
core4ai register --name "essay_prompt" \
    --message "Basic essay template" \
    "Write a well-structured essay on {{ topic }} that includes an introduction, body paragraphs, and conclusion."

# Register multiple prompts from a JSON file
core4ai register --file prompts.json

# List all available prompts
core4ai list

# Get details about a specific prompt
core4ai list --name "essay_prompt@production" --details

# Later, update the same prompt (creates a new version)
core4ai register --name "email_prompt" "Write an updated {{ formality }} email..."
```

### Basic Chat Interactions

```bash
# Simple query - Core4AI will match to the best prompt template
core4ai chat "Write about the future of AI"

# Get a simple response without enhancement details
core4ai chat --simple "Write an essay about climate change"

# See verbose output with prompt enhancement details
core4ai chat --verbose "Write an email to my boss about a vacation request"
```

## ğŸ’¡ Sample Prompts

Core4AI comes with several pre-registered prompt templates:

```bash
# Register sample prompts
core4ai register --samples
```

This will register the following prompt types:

| Prompt Type | Description | Sample Variables |
|-------------|-------------|------------------|
| `essay_prompt` | Academic writing | topic |
| `email_prompt` | Email composition | formality, recipient_type, topic |
| `technical_prompt` | Technical explanations | topic, audience |
| `creative_prompt` | Creative writing | genre, topic |
| `code_prompt` | Code generation | language, task, requirements |
| `summary_prompt` | Content summarization | content, length |

## ğŸ”„ Provider Configuration

### OpenAI

To use OpenAI, set your API key:

```bash
# Set environment variable (recommended)
export OPENAI_API_KEY="your-api-key-here"

# Or configure during setup
core4ai setup
```

Available models include:
- `gpt-3.5-turbo` (default)
- `gpt-4`
- `gpt-4-turbo`

### Ollama

To use Ollama:

1. [Install Ollama](https://ollama.ai/download) on your system
2. Start the Ollama server:
   ```bash
   ollama serve
   ```
3. Configure Core4AI:
   ```bash
   core4ai setup
   ```

## ğŸ“‹ Command Reference

| Command | Description | Examples |
|---------|-------------|----------|
| `core4ai setup` | Run the setup wizard | `core4ai setup` |
| `core4ai register` | Register a new prompt | `core4ai register --name "email_prompt" "Write a {{ formality }} email..."` |
| `core4ai list` | List available prompts | `core4ai list --details` |
| `core4ai chat` | Chat with enhanced prompts | `core4ai chat "Write about AI"` |
| `core4ai version` | Show version info | `core4ai version` |

## ğŸ§ª Running Tests

```bash
# Install development dependencies
pip install -e ".[dev]"

# Run all tests
pytest

# Run specific test category
pytest tests/unit
pytest tests/functional
pytest tests/integration
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“Š How Core4AI Works

Core4AI follows this workflow to process queries:

1. **Query Analysis**: Analyze the user's query to determine intent
2. **Prompt Matching**: Match the query to the most appropriate prompt template
3. **Parameter Extraction**: Extract relevant parameters from the query
4. **Template Application**: Apply the template with extracted parameters
5. **Validation**: Validate the enhanced prompt for completeness and accuracy
6. **Adjustment**: Adjust the prompt if validation issues are found
7. **AI Response**: Send the optimized prompt to the AI provider

## ğŸ“œ License

This project is licensed under the Apache License 2.0
