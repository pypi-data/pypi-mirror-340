# ---------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# ---------------------------------------------------------
from typing import Any, cast, Dict, List, Optional
from collections import OrderedDict
from datetime import datetime
import logging
import json
import numpy as np
import os
import pandas as pd
from shutil import copyfile

from azureml.core import Run
from azureml._restclient.constants import RunStatus
from azureml.core.model import Model
from azureml._common._error_definition.azureml_error import AzureMLError
import azureml.train.automl.runtime._hts.hts_events as hts_events
from azureml.automl.core._logging.event_logger import EventLogger
from azureml.automl.core.shared import constants, logging_utilities
from azureml.automl.core.shared._diagnostics.automl_error_definitions import ExplanationsNotFound
from azureml.automl.core.shared.exceptions import ClientException
from azureml.automl.core.shared.reference_codes import ReferenceCodes
from azureml.interpret._internal.explanation_client import ExplanationClient
from azureml.train.automl.constants import HTSConstants
import azureml.train.automl.runtime._hts.hts_runtime_utilities as hru
from interpret_community.explanation.explanation import GlobalExplanation
from azureml.train.automl.runtime._many_models.many_models_automl_train_driver import ManyModelsAutoMLTrainDriver

from .._solution_accelorators.data_models.arguments import Arguments
from .._solution_accelorators.data_models.hts_graph import Graph
from .._solution_accelorators.data_models.hts_node import Node
from .._solution_accelorators.data_models.status_record import StatusRecord


logger = logging.getLogger(__name__)


class HTSAutoMLTrainDriver(ManyModelsAutoMLTrainDriver):
    """Driver class for HTS AutoML train."""

    def __init__(
            self,
            current_step_run: Run,
            automl_settings: Dict[str, Any],
            args: Arguments
    ):
        super(HTSAutoMLTrainDriver, self).__init__(current_step_run, automl_settings, args)

        self.hts_graph = cast(Graph, args.hts_graph)

        self.event_dim = cast(Dict[str, str], args.event_logger_dim)
        self.event_logger = EventLogger(run=self.current_step_run)
        self.hts_hierarchy = self.hts_graph.hierarchy
        self.output_path = cast(str, args.output_path)
        self.agg_metadata = cast(str, args.input_metadata)
        self.enable_engineered_explanations = cast(bool, args.engineered_explanation)
        self.explainability = self.automl_settings.get('model_explainability', True)
        self._modify_settings_for_model_explain()
        # add the scenario identification to distinguish MM and HTS runs in AzureMLScenario
        self.automl_settings["automl_many_models_scenario"] = "many_models_hierarchy"
        self.hts_node = None  # type: Optional[Node]
        self._automl_run_properties = {}
        # mark the partition columns here to build the run properties
        self.partition_column_names = self.hts_graph.hierarchy_to_training_level
        os.environ['AUTOML_IGNORE_PACKAGE_VERSION_INCOMPATIBILITIES'] = "True"

    def run(self, input_data_file: str, output_data_file: str) -> Any:
        # build run properties before training.
        self.event_logger.log_event(hts_events.HTSAutoMLTrainStart(self.event_dim))
        self._find_hts_node(input_data_file)
        result = "{}: {}".format(input_data_file, self._get_node_id())
        # as the file might not from the same training, we need to skip this if not found in run id.
        if self.hts_node is None:
            self._console_writer.println("The data input is not generated by this run. Skipping now.")
            return [result]
        self._console_writer.println(
            "node id {} with parent nodes {}".format(
                self.hts_node.node_id, self.hts_node.node_parent_name_list))

        super(HTSAutoMLTrainDriver, self).run(input_data_file, output_data_file)
        self.event_logger.log_event(hts_events.HTSAutoMLTrainSaveMetadata(self.event_dim))
        # Using file copy here. If any future proportions calculation need to be added during training,
        # then this copy will be modified.
        self._copy_metadata_files(input_data_file)
        self.event_logger.log_event(hts_events.HTSAutoMLTrainEnd(self.event_dim))
        return output_data_file

    def pre_run(self, data: pd.DataFrame, file_name_with_extension: str) -> None:
        super(HTSAutoMLTrainDriver, self).pre_run(data, file_name_with_extension)
        # adding this logs as the one in AutoML may be disabled.
        self._console_writer.println("The input size is {}.".format(data.shape))

    def post_run(
            self, tags_dict: Dict[str, str], best_child_run: Run, current_run: Run, fitted_model: Model,
            start_time: datetime, input_data_file: str, model_name: str
    ) -> List[Any]:
        """Register the model and generating the logs."""
        result_list = super(HTSAutoMLTrainDriver, self).post_run(
            tags_dict, best_child_run, current_run, fitted_model, start_time, input_data_file, model_name
        )
        # Upload the explanations.
        try:
            self.save_explanations_or_raise(
                self.explainability, best_child_run, self.output_path,
                self._get_node_id(), self.agg_metadata, self.enable_engineered_explanations)
            if self.explainability:
                explain_status_record = StatusRecord(
                    self._get_node_parent_name_list(), StatusRecord.SUCCEEDED,
                    os.path.basename(input_data_file), self._get_run_id(current_run))
                self._save_status_records_to_file(
                    explain_status_record,
                    os.path.join(
                        self.output_path,
                        hru.get_explanation_info_file_name(self._get_file_name(input_data_file))))
        except Exception as error:
            if isinstance(error, ClientException) and error.error_code == ExplanationsNotFound().code:
                error_type = StatusRecord.get_error_type(error)
                # If the model_explainability was set to true, but the explanation has failed
                # we will fail the run.
                failed_reason = "Explanation failed for parent run {}. failed reason: {}\n\n".format(
                    self.current_step_run.id, error)
                self._console_writer.println(failed_reason)
                explain_status_record = StatusRecord(
                    self._get_node_parent_name_list(), StatusRecord.FAILED, os.path.basename(input_data_file),
                    self._get_run_id(current_run), error_type=error_type, error_message=failed_reason
                )
                self._save_status_records_to_file(
                    explain_status_record,
                    os.path.join(
                        self.output_path,
                        hru.get_explanation_info_file_name(self._get_file_name(input_data_file))))
            else:
                raise

        status = self._get_run_status(current_run)

        if status is not None and status.lower() in {RunStatus.COMPLETED.lower(), RunStatus.CANCELED.lower()}:
            self._record_successful_run(input_data_file, current_run)
        else:
            self._record_failed_run(input_data_file, current_run)

        self._console_writer.println("Training and model registration done.")
        return result_list

    def post_run_exception(
            self, tags_dict: Dict[str, str], current_run: Run,
            start_time: datetime, input_data_file: str, model_name: str, error: BaseException
    ) -> List[Any]:
        result_list = super(HTSAutoMLTrainDriver, self).post_run_exception(
            tags_dict, current_run, start_time, input_data_file, model_name, error
        )

        error_type = StatusRecord.get_error_type(error)
        failed_reason = "Pipeline parent run {}. failed reason: {}\n\n".format(
            self.current_step_run.id, error)
        self._console_writer.println(
            "Pipeline parent run {}. failed reason: {}\n\n".format(self.current_step_run.id, error))

        logging_utilities.log_traceback(error, logger)

        self._record_failed_run(input_data_file, current_run, error_type, failed_reason)

        return result_list

    def get_tag_dict(self, file_name_with_extension: str) -> Dict[str, str]:
        """
        Build the tags dict for the model.

        :param file_name_with_extension: The file name.
        :return: Dict of the model tags.
        """
        tags_dict = super(HTSAutoMLTrainDriver, self).get_tag_dict(file_name_with_extension)
        tags_dict.update({
            HTSConstants.MODEL_TAG_HIERARCHY: json.dumps(self._get_node_parent_name_list())})
        return tags_dict

    def get_hashed_model_string(self) -> str:
        return hru.get_model_hash(self._get_node_parent_name_list())

    def _get_node_parent_name_list(self) -> List[str]:
        if self.hts_node is None:
            return []
        else:
            return self.hts_node.node_parent_name_list

    def _get_node_id(self) -> str:
        if self.hts_node is None:
            return ''
        else:
            return self.hts_node.node_id

    def _get_run_status(self, current_run: Run) -> Optional[str]:
        return None if current_run is None else current_run.status

    def _get_run_id(self, current_run: Run) -> Optional[str]:
        return None if current_run is None else current_run.id

    def _get_file_name(self, filename_with_path: str) -> str:
        file_name, _ = os.path.splitext(os.path.basename(filename_with_path))
        return file_name

    def _find_hts_node(self, file_name_with_extension: str) -> None:
        """Find the HTS nodes."""
        # file_name is the node id here. the _ should be ".csv"
        file_name = self._get_file_name(file_name_with_extension)
        self.hts_node = self.hts_graph.get_node_by_id(file_name)

    def _record_successful_run(self, input_data_file: str, local_run: Optional[Run] = None) -> None:
        """Record the successful run and save the status record"""
        run_id = self._get_run_id(local_run)
        status_record = StatusRecord(
            self._get_node_parent_name_list(), StatusRecord.SUCCEEDED,
            os.path.basename(input_data_file), run_id)
        self._save_status_records_to_file(
            status_record,
            os.path.join(self.output_path, hru.get_run_info_filename(self._get_file_name(input_data_file))))

    def _record_failed_run(
            self,
            input_data_file: str,
            local_run: Optional[Run] = None,
            error_type: Optional[str] = None,
            failed_reason: Optional[str] = None) -> None:
        # There are 2 types of exceptions: 1) exceptions raises during the run and
        # 2) exceptions not raise but the run failed. We will treat the second one as system error now.
        if error_type is None and failed_reason is None:
            error_type = StatusRecord.SYSTEM_ERROR
            if local_run is not None:
                failed_reason = local_run.get_details().get("error")
        status_record = StatusRecord(
            self._get_node_parent_name_list(), StatusRecord.FAILED, os.path.basename(input_data_file),
            self._get_run_id(local_run), error_type=error_type, error_message=failed_reason
        )

        self._save_status_records_to_file(
            status_record,
            os.path.join(self.output_path, hru.get_run_info_filename(self._get_file_name(input_data_file))))

    def _save_status_records_to_file(self, status_record: StatusRecord, file_path: str) -> None:
        hru.dump_object_to_json(status_record, file_path)

    def _copy_metadata_files(self, input_data_file: str) -> None:
        file_name = self._get_file_name(input_data_file)
        before_training_proportions_file = hru.get_proportions_csv_filename(file_name)
        copyfile(os.path.join(
            self.agg_metadata, before_training_proportions_file),
            os.path.join(self.output_path, before_training_proportions_file))
        before_training_vocabulary_file = hru.get_node_columns_info_filename(file_name)
        copyfile(os.path.join(
            self.agg_metadata, before_training_vocabulary_file),
            os.path.join(self.output_path, before_training_vocabulary_file))

    def modify_run_properties(
            self,
            data: pd.DataFrame,
            file_path: str
    ) -> None:
        """
        Generate a dict for additional properties for an AutoML hierarchy run.

        :param data: Input data.
        :param file_path: The file path point to the file for training.
        """
        super(HTSAutoMLTrainDriver, self).modify_run_properties(data, file_path)
        hierarchy_level_run_data_tags = OrderedDict()
        for level, node_name in zip(
                self.hts_hierarchy[: len(self._get_node_parent_name_list())],
                self._get_node_parent_name_list()):
            hierarchy_level_run_data_tags[level] = node_name
        self._automl_run_properties.update({
            HTSConstants.RUN_PROPERTIES_HTS_HIERARCHY: self.hts_hierarchy,
            HTSConstants.RUN_PROPERTIES_MANY_MODELS_RUN: True,
            HTSConstants.RUN_PROPERTIES_INPUT_FILE: os.path.basename(file_path),
            HTSConstants.RUN_PROPERTIES_DATA_TAGS: json.dumps(hierarchy_level_run_data_tags)})

    def _modify_settings_for_model_explain(self) -> None:
        # Block non explainable models if the explanation is desired.
        if self.explainability:
            blocklist = self.automl_settings.get('blocked_models', [])
            if blocklist is None:
                blocklist = []
            blocked_by_explainability = set(
                constants._NonExplainableModels.FORECASTING).difference(set(blocklist))
            if isinstance(blocklist, str):
                blocklist = [blocklist]
            for model in constants._NonExplainableModels.FORECASTING:
                if model not in blocklist:
                    blocklist.append(model)
            self._console_writer.println(
                "The following non explainable models were blocked "
                "because the model_explainability is switched on: {}".format(blocked_by_explainability))
            self.automl_settings['blocked_models'] = blocklist
            self.automl_settings['enable_dnn'] = False

    def _get_explanation_before_aggregation(
            self,
            node_id: str, agg_metadata: str,
            explanation: GlobalExplanation) -> GlobalExplanation:
        """
        Get the feature matrix to reconstruct the importance of the raw features.

        :param node_id: The node_id to be used to identify the explanation.
        :param agg_metadata: The directory, containing metadata.
        :param explanation:  the explanat
        :return: the new explanation if working_dir contains the feature matrix or old explanation.
        """
        features_path = os.path.join(agg_metadata, hru.get_engineered_column_info_name(node_id))
        # If there is no file with feature matrix, do not correct for aggregation.
        if not os.path.isfile(features_path):
            self._console_writer.println('The information on aggregated column was not found.')
            return explanation
        with open(features_path, 'r') as fp:
            features_dict = json.load(fp)
        # Create the matrix of (raw_features, engineered_features) size.
        # Please note, that here we are treating features, generated by the data
        # aggregation as engineered.
        # Ones will be set on the intersection of the row and corresponding column,
        # if the raw feature was used to derive engineered column, otherwise 0 will be set.
        feature_map_lst = []  # type: List[np.ndarray]
        # The dictionary, mapping row column names to the row in feature matrix
        raw_names = {}  # type: Dict[str, int]
        # The list to store raw names in order.
        raw_names_lst = []  # type: List[str]
        for i in range(len(explanation.features)):
            name = explanation.features[i]
            raw_name = features_dict.get(name, name)
            if raw_name not in raw_names:
                # The feature was not seen before.
                raw_names[raw_name] = len(feature_map_lst)
                feature_map_lst.append(np.zeros(len(explanation.features)))
                raw_names_lst.append(raw_name)
            feature_map_lst[raw_names[raw_name]][i] = 1
        # Finally convert feature matrix to the np.ndarray and return new explanation.
        return explanation.get_raw_explanation(
            raw_feature_names=raw_names_lst,
            feature_maps=[np.array(feature_map_lst)])

    def _save_explanations(
            self,
            raw: bool, client: ExplanationClient, output_dir: str,
            node_id: str, agg_metadata: str) -> bool:
        """
        Save model explanations to the artifacts.

        :param raw: If True, save raw features. Otherwise, save engineered features.
        :param node_id: The node_id to be used to identify the explanation.
        :param agg_metadata: The directory, containing metadata.
        :return: True if the explanations were found, false otherwise.
        """
        exp_type = (
            HTSConstants.EXPLANATIONS_RAW_FEATURES if raw else HTSConstants.EXPLANATIONS_ENGINEERED_FEATURES)
        if client.list_model_explanations(raw=raw):
            explanation = client.download_model_explanation(raw=raw)
            if raw:
                self._console_writer.println("Calculating explanations for raw features.")
                explanation = self._get_explanation_before_aggregation(node_id, agg_metadata, explanation)
            expl_dict = explanation.get_feature_importance_dict()
            artifact_file_name = hru.get_explanation_artifact_name(raw, node_id)
            file_path = os.path.join(output_dir, artifact_file_name)
            with open(file_path, 'w') as f:
                json.dump(expl_dict, f)
            self._console_writer.println(
                "The {} feature explanations were saved to the output directory.".format(exp_type))
            return True

        self._console_writer.println("No {} feature explanations were found.".format(exp_type))
        return False

    def save_explanations_or_raise(
            self,
            explainability: bool, best_child_run: Run,
            output_dir: str, node_id: str, agg_metadata: str,
            enable_engineered_explanations: bool
    ) -> None:
        """
        Save the model explanations if explanations are desired, raise exception if explanations are not available.

        :param explainability: The model explainability.
        :param best_child_run: The run for which we need to upload explanations.
        :param output_dir: The directory, where the explanations will be stored.
        :param node_id: The node_id to be used to identify the explanation.
        :param agg_metadata: The directory, containing metadata.
        :param enable_engineered_explanations: If True, the engineered feature explanations
                                               will be generated.
        :raises: ConfigException
        """
        if not explainability:
            return
        expl_dir = os.path.join(output_dir, HTSConstants.HTS_DIR_EXPLANATIONS)
        os.makedirs(expl_dir, exist_ok=True)
        client = ExplanationClient.from_run(best_child_run)
        raw_expl_found = self._save_explanations(True, client, expl_dir, node_id, agg_metadata)
        if enable_engineered_explanations:
            engineered_expl_found = self._save_explanations(False, client, expl_dir, node_id, agg_metadata)
        else:
            # If engineered features explanations are not desired, we do not check for it,
            # in this case we will not show that we were unable to find engineered features
            # explanations in the error.
            engineered_expl_found = True
        if not raw_expl_found or not engineered_expl_found:
            if not raw_expl_found and not engineered_expl_found:
                # Remove the directory as we did not generate predictions.
                os.rmdir(expl_dir)
                exp_type = '{} and {}'.format(
                    HTSConstants.EXPLANATIONS_RAW_FEATURES,
                    HTSConstants.EXPLANATIONS_ENGINEERED_FEATURES)
            elif not raw_expl_found:
                if not enable_engineered_explanations:
                    # Remove directory if raw feature explanations are not found
                    # and engineered features explanations are disabled.
                    os.rmdir(expl_dir)
                exp_type = HTSConstants.EXPLANATIONS_RAW_FEATURES
            else:
                exp_type = HTSConstants.EXPLANATIONS_ENGINEERED_FEATURES
            raise ClientException._with_error(
                AzureMLError.create(
                    ExplanationsNotFound,
                    exp_type=exp_type,
                    target='explanations',
                    reference_code=ReferenceCodes._HTS_NO_EXPLANATION_DOWNLOAD)
            )
