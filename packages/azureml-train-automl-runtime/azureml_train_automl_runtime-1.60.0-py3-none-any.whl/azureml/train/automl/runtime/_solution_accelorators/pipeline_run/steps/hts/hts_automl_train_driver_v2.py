# ---------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# ---------------------------------------------------------
from typing import Any, cast, Dict, List, Optional
from collections import OrderedDict
from datetime import datetime
import logging
import json
import numpy as np
import os
import pandas as pd
from shutil import copyfile

from azureml.core import Run
from azureml.core.model import Model
from azureml._common._error_definition.azureml_error import AzureMLError
from azureml.automl.core.shared import constants, logging_utilities
from azureml.automl.core.shared._diagnostics.automl_error_definitions import ExplanationsNotFound
from azureml.automl.core.shared.exceptions import ClientException
from azureml.automl.core.shared.reference_codes import ReferenceCodes
from azureml.interpret._internal.explanation_client import ExplanationClient
from interpret_community.explanation.explanation import GlobalExplanation

from ....data_models.arguments import Arguments
from ....data_models.hts_graph import Graph
from ....data_models.hts_node import Node
from ....data_models.status_record import StatusRecord
from ....constants import PipelineConstants
from ....utilities import logging_utilities as lu
from ....utilities.events.hts_automl_train_events import (
    HTSAutoMLTrainDriverRunStart,
    HTSAutoMLTrainDriverRunEnd,
    HTSAutoMLTrainDriverSaveMetadata
)
from ..automl_prs_train_driver import AutoMLPRSTrainDriver
from .hts_data_aggregation_driver_v2 import HTSDataAggregationDriverV2


logger = logging.getLogger(__name__)


class HTSAutoMLTrainDriverV2(AutoMLPRSTrainDriver):
    """Driver class for HTS AutoML train."""
    POSTFIX_EXPLANATION_INFO_JSON = "_explanation_info.json"
    EXPLANATIONS_RAW_FEATURES = 'raw'
    EXPLANATIONS_ENGINEERED_FEATURES = 'engineered'
    HTS_DIR_EXPLANATIONS = "explanations"
    MODEL_TAG_HIERARCHY = "Hierarchy"
    RUN_PROPERTIES_HTS_HIERARCHY = "hts_hierarchy"

    def __init__(
            self,
            current_step_run: Run,
            automl_settings: Dict[str, Any],
            args: Arguments,
            **kwargs: Any
    ) -> None:
        super().__init__(current_step_run, automl_settings, args, **kwargs)
        # add the scenario identification to distinguish MM and HTS runs in AzureMLScenario
        self.automl_settings["automl_many_models_scenario"] = "many_models_hierarchy"

        self.hts_graph = cast(Graph, args.hts_graph)
        self.hts_hierarchy = self.hts_graph.hierarchy
        self.enable_engineered_explanations = cast(bool, args.engineered_explanation)
        self.explainability = self.automl_settings.get('model_explainability', True)
        self._modify_settings_for_model_explain()
        self.hts_node = None  # type: Optional[Node]
        self.agg_metadata = cast(str, args.input_metadata)

    @lu.event_log_wrapped(HTSAutoMLTrainDriverRunStart(), HTSAutoMLTrainDriverRunEnd())
    def run(self, input_data_file: str, output_data_file: str) -> Any:
        # build run properties before training.
        self._find_hts_node(input_data_file)
        result = "{}: {}".format(input_data_file, self._get_node_id())
        # as the file might not from the same training, we need to skip this if not found in run id.
        if self.hts_node is None:
            self._console_writer.println("The data input is not generated by this run. Skipping now.")
            return [result]
        self._console_writer.println(
            "node id {} with parent nodes {}".format(
                self.hts_node.node_id, self.hts_node.node_parent_name_list))

        super(HTSAutoMLTrainDriverV2, self).run(input_data_file, output_data_file)
        self.event_logger.log_event(HTSAutoMLTrainDriverSaveMetadata(self.event_logger_additional_fields))
        # Using file copy here. If any future proportions calculation need to be added during training,
        # then this copy will be modified.
        self._copy_metadata_files(input_data_file)
        return output_data_file

    def pre_run(self, data: pd.DataFrame, file_name_with_extension: str) -> None:
        super(HTSAutoMLTrainDriverV2, self).pre_run(data, file_name_with_extension)
        # adding this logs as the one in AutoML may be disabled.
        self._console_writer.println("The input size is {}.".format(data.shape))

    def post_run(
            self, tags_dict: Dict[str, str], best_child_run: Run, current_run: Run, fitted_model: Model,
            start_time: datetime, input_data_file: str, model_name: str
    ) -> List[Any]:
        """Register the model and generating the logs."""
        result_list = super(HTSAutoMLTrainDriverV2, self).post_run(
            tags_dict, best_child_run, current_run, fitted_model, start_time, input_data_file, model_name
        )
        # Upload the explanations.
        try:
            self.save_explanations_or_raise(
                self.explainability, best_child_run, self.output_path,
                self._get_node_id(), self.agg_metadata, self.enable_engineered_explanations)
            if self.explainability:
                explain_status_record = StatusRecord(
                    self._get_node_parent_name_list(), StatusRecord.SUCCEEDED,
                    os.path.basename(input_data_file), self._get_run_id(current_run))
                self._save_status_records_to_file(
                    explain_status_record,
                    os.path.join(
                        self.output_path,
                        self.get_explanation_info_file_name(self._get_file_name(input_data_file))))
        except Exception as error:
            if isinstance(error, ClientException) and error.error_code == ExplanationsNotFound().code:
                error_type = StatusRecord.get_error_type(error)
                # If the model_explainability was set to true, but the explanation has failed
                # we will fail the run.
                failed_reason = "Explanation failed for parent run {}. failed reason: {}\n\n".format(
                    self.current_step_run.id, error)
                self._console_writer.println(failed_reason)
                explain_status_record = StatusRecord(
                    self._get_node_parent_name_list(), StatusRecord.FAILED, os.path.basename(input_data_file),
                    self._get_run_id(current_run), error_type=error_type, error_message=failed_reason
                )
                self._save_status_records_to_file(
                    explain_status_record,
                    os.path.join(
                        self.output_path,
                        self.get_explanation_info_file_name(self._get_file_name(input_data_file))))
            else:
                raise

        return result_list

    def get_tag_dict(self, file_name_with_extension: str) -> Dict[str, str]:
        """
        Build the tags dict for the model.

        :param file_name_with_extension: The file name.
        :return: Dict of the model tags.
        """
        tags_dict = super(HTSAutoMLTrainDriverV2, self).get_tag_dict(file_name_with_extension)
        tags_dict.update({
            HTSAutoMLTrainDriverV2.MODEL_TAG_HIERARCHY: json.dumps(self._get_node_parent_name_list())})
        return tags_dict

    def _get_node_parent_name_list(self) -> List[str]:
        if self.hts_node is None:
            return []
        else:
            return self.hts_node.node_parent_name_list

    def _get_node_id(self) -> str:
        if self.hts_node is None:
            return ''
        else:
            return self.hts_node.node_id

    def _find_hts_node(self, file_name_with_extension: str) -> None:
        """Find the HTS nodes."""
        # file_name is the node id here. the _ should be ".csv" or ".parquet"
        file_name = self._get_file_name(file_name_with_extension)
        self.hts_node = self.hts_graph.get_node_by_id(file_name)

    def _copy_metadata_files(self, input_data_file: str) -> None:
        file_name = self._get_file_name(input_data_file)
        before_training_proportions_file = HTSDataAggregationDriverV2.get_proportions_filename(file_name)
        copyfile(os.path.join(
            self.agg_metadata, before_training_proportions_file),
            os.path.join(self.output_path, before_training_proportions_file))
        before_training_vocabulary_file = HTSDataAggregationDriverV2.get_node_columns_info_filename(file_name)
        copyfile(os.path.join(
            self.agg_metadata, before_training_vocabulary_file),
            os.path.join(self.output_path, before_training_vocabulary_file))

    def modify_run_properties(
            self,
            data: pd.DataFrame,
            file_name_with_extension: str
    ) -> None:
        """
        Generate a dict for additional properties for an AutoML hierarchy run.

        :param data: Input data.
        :param file_name_with_extension: The file path point to the file for training.
        """
        super(HTSAutoMLTrainDriverV2, self).modify_run_properties(data, file_name_with_extension)
        hierarchy_level_run_data_tags = OrderedDict()
        for level, node_name in zip(
                self.hts_hierarchy[: len(self._get_node_parent_name_list())],
                self._get_node_parent_name_list()):
            hierarchy_level_run_data_tags[level] = node_name
        self._automl_run_properties.update({
            HTSAutoMLTrainDriverV2.RUN_PROPERTIES_HTS_HIERARCHY: self.hts_hierarchy})

    def _modify_settings_for_model_explain(self) -> None:
        # Block non explainable models if the explanation is desired.
        if self.explainability:
            blocklist = self.automl_settings.get('blocked_models', [])
            if blocklist is None:
                blocklist = []
            blocked_by_explainability = set(
                constants._NonExplainableModels.FORECASTING).difference(set(blocklist))
            if isinstance(blocklist, str):
                blocklist = [blocklist]
            for model in constants._NonExplainableModels.FORECASTING:
                if model not in blocklist:
                    blocklist.append(model)
            self._console_writer.println(
                "The following non explainable models were blocked "
                "because the model_explainability is switched on: {}".format(blocked_by_explainability))
            self.automl_settings['blocked_models'] = blocklist
            self.automl_settings['enable_dnn'] = False

    def _get_explanation_before_aggregation(
            self,
            node_id: str, agg_metadata: str,
            explanation: GlobalExplanation) -> GlobalExplanation:
        """
        Get the feature matrix to reconstruct the importance of the raw features.

        :param node_id: The node_id to be used to identify the explanation.
        :param agg_metadata: The directory, containing metadata.
        :param explanation:  the explanat
        :return: the new explanation if working_dir contains the feature matrix or old explanation.
        """
        features_path = os.path.join(agg_metadata, HTSDataAggregationDriverV2.get_engineered_column_info_name(node_id))
        # If there is no file with feature matrix, do not correct for aggregation.
        if not os.path.isfile(features_path):
            self._console_writer.println('The information on aggregated column was not found.')
            return explanation
        with open(features_path, 'r') as fp:
            features_dict = json.load(fp)
        # Create the matrix of (raw_features, engineered_features) size.
        # Please note, that here we are treating features, generated by the data
        # aggregation as engineered.
        # Ones will be set on the intersection of the row and corresponding column,
        # if the raw feature was used to derive engineered column, otherwise 0 will be set.
        feature_map_lst = []  # type: List[np.ndarray]
        # The dictionary, mapping row column names to the row in feature matrix
        raw_names = {}  # type: Dict[str, int]
        # The list to store raw names in order.
        raw_names_lst = []  # type: List[str]
        for i in range(len(explanation.features)):
            name = explanation.features[i]
            raw_name = features_dict.get(name, name)
            if raw_name not in raw_names:
                # The feature was not seen before.
                raw_names[raw_name] = len(feature_map_lst)
                feature_map_lst.append(np.zeros(len(explanation.features)))
                raw_names_lst.append(raw_name)
            feature_map_lst[raw_names[raw_name]][i] = 1
        # Finally convert feature matrix to the np.ndarray and return new explanation.
        return explanation.get_raw_explanation(
            raw_feature_names=raw_names_lst,
            feature_maps=[np.array(feature_map_lst)])

    def _save_explanations(
            self,
            raw: bool, client: ExplanationClient, output_dir: str,
            node_id: str, agg_metadata: str) -> bool:
        """
        Save model explanations to the artifacts.

        :param raw: If True, save raw features. Otherwise, save engineered features.
        :param node_id: The node_id to be used to identify the explanation.
        :param agg_metadata: The directory, containing metadata.
        :return: True if the explanations were found, false otherwise.
        """
        exp_type = (
            self.EXPLANATIONS_RAW_FEATURES if raw else self.EXPLANATIONS_ENGINEERED_FEATURES)
        if client.list_model_explanations(raw=raw):
            explanation = client.download_model_explanation(raw=raw)
            if raw:
                self._console_writer.println("Calculating explanations for raw features.")
                explanation = self._get_explanation_before_aggregation(node_id, agg_metadata, explanation)
            expl_dict = explanation.get_feature_importance_dict()
            artifact_file_name = HTSAutoMLTrainDriverV2.get_explanation_artifact_name(raw, node_id)
            file_path = os.path.join(output_dir, artifact_file_name)
            with open(file_path, 'w') as f:
                json.dump(expl_dict, f)
            self._console_writer.println(
                "The {} feature explanations were saved to the output directory.".format(exp_type))
            return True

        self._console_writer.println("No {} feature explanations were found.".format(exp_type))
        return False

    def save_explanations_or_raise(
            self,
            explainability: bool, best_child_run: Run,
            output_dir: str, node_id: str, agg_metadata: str,
            enable_engineered_explanations: bool
    ) -> None:
        """
        Save the model explanations if explanations are desired, raise exception if explanations are not available.

        :param explainability: The model explainability.
        :param best_child_run: The run for which we need to upload explanations.
        :param output_dir: The directory, where the explanations will be stored.
        :param node_id: The node_id to be used to identify the explanation.
        :param agg_metadata: The directory, containing metadata.
        :param enable_engineered_explanations: If True, the engineered feature explanations
                                               will be generated.
        :raises: ConfigException
        """
        if not explainability:
            return
        expl_dir = os.path.join(output_dir, HTSAutoMLTrainDriverV2.HTS_DIR_EXPLANATIONS)
        os.makedirs(expl_dir, exist_ok=True)
        client = ExplanationClient.from_run(best_child_run)
        raw_expl_found = self._save_explanations(True, client, expl_dir, node_id, agg_metadata)
        if enable_engineered_explanations:
            engineered_expl_found = self._save_explanations(False, client, expl_dir, node_id, agg_metadata)
        else:
            # If engineered features explanations are not desired, we do not check for it,
            # in this case we will not show that we were unable to find engineered features
            # explanations in the error.
            engineered_expl_found = True
        if not raw_expl_found or not engineered_expl_found:
            if not raw_expl_found and not engineered_expl_found:
                # Remove the directory as we did not generate predictions.
                os.rmdir(expl_dir)
                exp_type = '{} and {}'.format(
                    HTSAutoMLTrainDriverV2.EXPLANATIONS_RAW_FEATURES,
                    HTSAutoMLTrainDriverV2.EXPLANATIONS_ENGINEERED_FEATURES)
            elif not raw_expl_found:
                if not enable_engineered_explanations:
                    # Remove directory if raw feature explanations are not found
                    # and engineered features explanations are disabled.
                    os.rmdir(expl_dir)
                exp_type = HTSAutoMLTrainDriverV2.EXPLANATIONS_RAW_FEATURES
            else:
                exp_type = HTSAutoMLTrainDriverV2.EXPLANATIONS_ENGINEERED_FEATURES
            raise ClientException._with_error(
                AzureMLError.create(
                    ExplanationsNotFound,
                    exp_type=exp_type,
                    target='explanations',
                    reference_code=ReferenceCodes._HTS_NO_EXPLANATION_DOWNLOAD)
            )

    @property
    def run_type(self) -> str:
        return PipelineConstants.RUN_TYPE_HTS

    @staticmethod
    def get_explanation_info_file_name(filename: str) -> str:
        """
        Get the name of an intermediate explanation result file.

        :param filename: The base file name.
        :return: The name of a file.
        """
        return "{}{}".format(filename, HTSAutoMLTrainDriverV2.POSTFIX_EXPLANATION_INFO_JSON)

    @staticmethod
    def get_explanation_artifact_name(raw: bool, node_id: str) -> str:
        """
        Get the name of a JSON serialized dictionary with raw or engineered features explanations.

        :param raw: If true the name of a raw feature artifact will be returned.
        :param node_id: The node id in the graph.
        """
        return '{}_explanation_{}.json'.format(
            HTSAutoMLTrainDriverV2.EXPLANATIONS_RAW_FEATURES if raw else
            HTSAutoMLTrainDriverV2.EXPLANATIONS_ENGINEERED_FEATURES, node_id)

    @property
    def _data_identifier(self) -> List[str]:
        return self._get_node_parent_name_list()
