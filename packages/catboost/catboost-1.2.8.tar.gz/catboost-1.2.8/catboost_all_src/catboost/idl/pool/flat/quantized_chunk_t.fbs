namespace NCB.NIdl;

// Depending on feature universe size it may be encoded using different number of bits. E.g.
// feature only has values "yes" and "no", then its per-document value may be efficiently encoded
// using only one bit.
//
enum EBitsPerDocumentFeature : ubyte {
    BPDF_UKNOWN = 0,

    BPDF_1  = 1,
    BPDF_2  = 2,
    BPDF_4  = 4,
    BPDF_8  = 8,
    BPDF_16 = 16,
    BPDF_32 = 32,
    BPDF_64 = 64
}

// Represents chunk of feature values. Chunk itself doesn't store information on feature
// index, type or range of documents, it's expected that user will store this information somewhere.
//
// One of possible usages will be to organize quantized pool in a following manner:
//
// | feature_index | document_offset | chunk_size | chunk |
//
// Where:
// - `features_index` -- feature index.
// - `document_offset` -- index of the first document whose `features_index` feature value is stored
//     in the chunk.
// - `chunk_size` -- number of feature values stored in the chunk
// - `chunk` -- blob than can be read with `GetRoot<TQuantizedFeatureChunk>(chunk.data())`
//
// It also may be useful to apply some compression algorithm to `chunk` (if you are going to store
// it in a distributed storage).
//
table TQuantizedFeatureChunk {
    // Number of bits used to store per-document quantized feature value.
    //
    // NOTE: If you have feature quantization schema then one of following predicates should be
    // true:
    // - `ClosesPowerOf2GreaterOrEqual(Borders.size()) == BitsPerDocument`
    // - `ClosesPowerOf2GreaterOrEqual(UniqueHashes.size()) == BitsPerDocument`
    //
    // depending on type of feature (numeric or categorical).
    //
    BitsPerDocument:EBitsPerDocumentFeature;

    // Quantized feature values serialized one after another.
    //
    // TODO(yazevnul): elaborate on endiannes (right now it will be LE, because of Intel CPUs).
    Quants:[ubyte];
}
