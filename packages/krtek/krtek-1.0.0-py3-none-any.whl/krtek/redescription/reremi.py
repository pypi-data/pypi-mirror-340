"""
    This file contains the implementation of the Redescription Mining method ReRemi for generating and evaluating association rules on the given dataset.
"""

import numpy as np
import pandas as pd

from typing import List
from typing import Sequence as SequenceType
from datetime import datetime
from timeit import default_timer as timer
from itertools import product

from .trie import BitwiseTrie
from ..quantifiers import Quantifier, Jaccard
from ..coefficients import Coefficient, Sequence, Subset
from ..logic import LogicalOperator, BoolAttribute, BoolAttributeQuery, Rule
from ..utils import _unpack, colored, Colors
from ..computation import get_query_card, get_literal_card


class ReReMiMiner():
    """Implementation of ReReMiMiner method for generating and evaluating association rules on the given dataset. The method is based on the paper: From black and white to full color **[3]**.

    Attributes:
        data (pd.DataFrame): The dataset that will be used to generate rules.
        lhs_attributes (List[str]): Attributes that will be used to generate left-hand side of the rule.
        rhs_attributes (List[str]): Attributes that will be used to generate right-hand side of the rule.
        quantifier (Coefficient, optional): Quantifier (distance function) that will be used to evaluate quality of rules. Defaults to Jaccard.
        initial_pair_size (int, optional): Size of initial list of pairs which will be used to generate rules. Defaults to 0.
        beam_search_size (int, optional): Size of beam search for each initial redescription. Defaults to 0.
        max_side_size (int, optional): Maximum size of the side of the rule. Defaults to 0.
        min_accuracy (float, optional): Minimum accuracy that the rule must have to be considered valid. Defaults to 0.
        redundancy (bool, optional): Whether to consider the generation of redundant rules. Defaults to False.
        operators (List[str], optional): A list of operators that will be used to generate rules.. Defaults to ["AND"].
        category_coefficient (dict[Coefficient], optional): How should attributes or column types should be generated. Defaults to None.

    For more information about the parameters, see the class attributes in the class documentation.
    """

    # Main attributes
    data: pd.DataFrame
    "The dataset that will be used to generate rules."
    lhs_attributes: List[str]
    "Attributes that will be used to generate left-hand side of the rule."
    rhs_attributes: List[str]
    "Attributes that will be used to generate right-hand side of the rule."
    quantifier: Quantifier
    "Quantifier that will be used to evaluate quality of rules."

    # Setting attributes
    initial_pair_size: int
    "Size of initial list of pairs which will be used to generate rules. If set to 0, the method will generate all possible pairs."
    beam_search_size: int
    "Size of list that will be used to store the best redescriptions for each initial redescription. If set to 0, the method will get only the best redescription."
    max_side_size: int
    "Maximum size of the side of the rule. If set to 0, the method will generate rules with no restrictions on the size of the side."
    min_accuracy: float
    "Minimum accuracy that the rule must have to be considered valid."
    redundancy: bool
    "Flag that indicates if the redundancy should be considered when generating rules. If set to True, the method will generate all possible rules, even if they are redundant. If set to False, the method will generate only non-redundant rules."
    operators: List[str]
    "A list of operators that will be used to generate rules. Supported operators are 'AND', 'OR', 'NOT'. The default list contains only 'AND' operator."
    category_coefficient: dict[str, Coefficient]
    """A dictionary of atributes and coefficients that will be used to evaluate quality of rules for different attribute types.

    The default dictionary contains the following:
        - "category": Subset()
        - "object": Subset(1)
        - "bool": Subset(1, 2)

    The dictionary can be extended with custom coefficients for specific attribute types:
        - "Arctic fox": OneCategory(True)
        - "category": Subset(1, 4)
    """

    book: "BookKeeping"
    "Book-keeping structure for already seen redescription."
    result: List[Rule]
    "The list of rules that were generated by the FourFtMiner method."

    def __init__(self,
                 data: pd.DataFrame,
                 lhs_attributes: SequenceType[str],
                 rhs_attributes: SequenceType[str],
                 quantifier: Quantifier = Jaccard(),
                 initial_pair_size: int = 0,
                 beam_search_size: int = 0,
                 max_side_size: int = 0,
                 min_accuracy: float = 0,
                 redundancy: bool = False,
                 operators: List[str] = ["AND"],
                 category_coefficient: dict[str, Coefficient] = {}
                 ):
        "Initializes the ReReMiMiner class."

        self.data = data
        # TODO: Inmutability of the data
        self.rhs_attributes = list(rhs_attributes)
        self.lhs_attributes = list(lhs_attributes)

        # Book-keeping structure for already seen redescription
        self.book = BookKeeping(self,
                                self.rhs_attributes,
                                self.lhs_attributes
                                )

        # Parameters
        self.initial_pair_size = initial_pair_size
        self.beam_search_size = beam_search_size
        self.max_side_size = max_side_size
        self.min_accuracy = min_accuracy
        self.redundancy = redundancy
        self.operators = operators
        self.quantifier = quantifier

        self.category_coefficient = {
                "category": Subset(1),
                "object": Subset(1),
                "bool": Subset(1, 1)
        }

        if len(category_coefficient) > 0:
            for category, coefficient in category_coefficient.items():
                self.category_coefficient[category] = coefficient

        self.result = []
        self._run_info = {}

    def print_run_info(self):
        "Prints the information about the last run of the ReReMi method."
        if self._run_info is None:
            return

        print(f"ReReMiMiner run info:")
        print(f"\tTime start: {self._run_info['time_start']}")
        print(f"\tTime total: {self._run_info['time_total']} seconds")
        print(f"\tNumber of rules: {self._run_info['number_of_rules']}")
        print(f"\tNumber of verifications: {self._run_info['number_of_verifications']}")

    def _restart(self):
        "Restart the ReReMi method."
        self.result = []
        self._run_info = {
            "time_start": datetime.now(),
            "time_total": 0,
            "number_of_rules": 0,
            "number_of_verifications": 0,
        }
        self.book = BookKeeping(self, self.rhs_attributes, self.lhs_attributes)

        relevant_attributes = self.lhs_attributes + self.rhs_attributes
        self._attribute_types = self.data[relevant_attributes].dtypes
        self._cards = pd.get_dummies(self.data[relevant_attributes])

    def run(self):
        "Runs the ReReMi method based on the given parameters."
        self._restart()

        print("Starting the task")
        task_run_start = timer()
        results = []

        # Step 1: Generate initial pairs
        print("Generating intial pairs")
        initial_pairs = self._generate_initial_pairs()
        print(len(initial_pairs), "initial pairs generated")

        if self.max_side_size != 1:
            # Step 2: Extend each initial pair
            print("Searching for extesions")

            for pair in initial_pairs:
                new_redescriptions = [pair]
                # Step 2.1: Check if is possible to extend
                # Check if there are fr ee attributes for either one or the other side
                # free variables are variables that can be used to expand given redescription
                candidates = []
                if len(self._free(pair, side="lhs")) or len(self._free(pair, side="rhs")):
                    candidates = [pair]

                # Step 2.2: Try extending candidates
                while len(candidates):
                    # Step 2.2.1: Extend all candidates
                    candidates = self._greedy_extend(candidates)
                    new_redescriptions.extend(candidates)

                    # Step 2.2.2: Filter candidates that will be extended
                    # Select only beam_search_size best from candidates
                    # Then filter all that can't be extended
                    candidates = self._filter_candidates(candidates)

                # Step 2.3: Add new redescriptions to final results
                results.extend(new_redescriptions)
        else:
            # Max side size is set to 1.
            results = initial_pairs

        # Step 3: Set new result
        print("Postprocessing")
        sorted_redescription = sorted(results, reverse=True)
        for rule in sorted_redescription:
            rule.posprocessing()
        self.result = sorted_redescription

        task_run_stop = timer()
        self._run_info["time_total"] = task_run_stop - task_run_start
        self._run_info["number_of_rules"] = len(self.result)

        print("End of task")
        return self.result

    def _filter_candidates(self, candidates):
        "Filter candidates that can be extended in next iteration."
        # Select only beam_search_size best from candidates
        if self.beam_search_size > 0:
            candidates = sorted(candidates, reverse=True)
            candidates = candidates[:self.beam_search_size]

        # Filter all that can't be extended
        filtered = []
        for redescription in candidates:
            # Check if redescription can be extended on either side
            if not len(self._free(redescription, side="lhs")) and not len(self._free(redescription, side="rhs")):
                continue

            filtered.append(redescription)
        return filtered

    def _free(self, redescription: Rule, side: str) -> np.ndarray:
        """Return free attributes for given redescription and side. Free attributes are attributes that can be used to extend the redescription on the given side and it do not create already seen redescription."""
        # Check max side size
        side_attributes = getattr(redescription, side).attributes
        if len(side_attributes) >= self.max_side_size:
            return np.array([])

        # Check already seen redescriptions with one step extension on one side
        already_seen = self.book.search(side, redescription)
        bitarray = np.array([[bool(int(bit)) for bit in bitstring] for bitstring in already_seen])

        # Which attributes are not free
        attribute_mask = np.logical_or.reduce(bitarray, 0)

        # Get free attributes index
        free_mask = np.logical_not(attribute_mask)

        if side == "lhs":
            return np.array(self.lhs_attributes)[free_mask]
        return np.array(self.rhs_attributes)[free_mask]

    def _greedy_extend(self, candidates: List[Rule]) -> List[Rule]:
        "Greedily extend all candidates and return only the best redescriptions."
        new_redescriptions = []

        # For each candidate generate new possible redescriptions
        for redescription in candidates:
            left_card = get_query_card(self._cards, redescription.lhs, self._attribute_types)
            right_card = get_query_card(self._cards, redescription.rhs, self._attribute_types)

            # E_xy is a boolean array indicating if rows in the DataFrame satisfy the given sides
            # Sum of each of these array (E_1,1, E_1,0, E_0,1, E_0,0) are equal to quadruple a, b, c, d (contingency table in GUHA)
            # E_1,1 - row satisfies both sides
            e_11 = np.logical_and(left_card, right_card)
            # E_1,0 - row satisfies left side but not right side
            e_10 = np.logical_and(left_card, np.logical_not(right_card))
            # E_0,1 - row satisfies right side but not left side
            e_01 = np.logical_and(np.logical_not(left_card), right_card)
            # E_0,0 - row satisfies neither side
            e_00 = np.logical_and(np.logical_not(left_card), np.logical_not(right_card))

            # Chose side to extend
            for side in ["lhs", "rhs"]:
                result = self._generate_extend(redescription, side, e_11, e_10, e_01, e_00, left_card, right_card)
                new_redescriptions.extend(result)

        return new_redescriptions

    def _generate_extend(self, redescription: Rule, side, e_11, e_10, e_01, e_00, left_card, right_card) -> List[Rule]:
        "Generate all possible redescriptions by extending given redescription on one side by appending specified operators and literals that are free."
        left_attributes = redescription.lhs.attributes
        right_attributes = redescription.rhs.attributes
        new_redescriptions = []

        def create_new_redescription(contingency_table, part_of_query):
            "Auxiliary function for creating new redescription."
            new = Rule(redescription.lhs, redescription.rhs, redescription.quantifiers, contingency_table)
            # Add new literal, operator and negation information to the side
            getattr(new, side).add(*part_of_query)
            return new

        # Extend side with free attributes and operators
        for attribute in self._free(redescription, side):
            # List of candidates for each operator extension option (i.e. AND, AND NOT, OR, OR NOT)
            candidates = [[], [], [], []]

            for literal in self._categories(attribute):
                # Function to calculate E_x,y
                l_card = get_literal_card(self._cards, literal, self._attribute_types)

                def land(e):
                    # Function to calculate logical and with l_card
                    return np.logical_and(e, l_card)

                def lor(e):
                    # Function to calculate logical or with l_card
                    return np.logical_or(e, l_card)

                def s(n):
                    # Function to calculate size
                    return np.sum(n)

                if "AND" in self.operators:
                    # Formula 1: side and literal
                    a = s(land(e_11))
                    b = s(land(left_card)) - a if side == "lhs" else s(left_card) - a
                    c = s(right_card) - a if side == "lhs" else s(land(right_card)) - a
                    d = self.data.shape[0] - a - b - c

                    accuracy = self.quantifier.calculate([a, b, c, d])
                    self._run_info["number_of_verifications"] += len(new_redescriptions)
                    if accuracy >= self.min_accuracy:
                        new = create_new_redescription([a, b, c, d], (literal, LogicalOperator.CONJUNCTION))
                        candidates[0].append(new)

                    # Formula 2: side and (not literal)
                    if "NOT" in self.operators:
                        a = s(e_11) - a
                        b = s(e_10) - b if side == "lhs" else s(left_card) - a
                        c = s(right_card) - a if side == "lhs" else s(e_01) - c
                        d = self.data.shape[0] - a - b - c

                        accuracy = self.quantifier.calculate([a, b, c, d])
                        self._run_info["number_of_verifications"] += len(new_redescriptions)
                        if accuracy >= self.min_accuracy:
                            new = create_new_redescription([a, b, c, d], (literal, LogicalOperator.CONJUNCTION, True))
                            candidates[1].append(new)

                if "OR" in self.operators:
                    # Formula 3: side or literal
                    a = s(e_11) + s(land(e_01)) if side == "lhs" else s(e_11) + s(land(e_10))
                    b = s(lor(left_card)) - a if side == "lhs" else s(left_card) - a
                    c = s(right_card) - a if side == "lhs" else s(lor(right_card)) - a
                    d = self.data.shape[0] - a - b - c

                    accuracy = self.quantifier.calculate([a, b, c, d])
                    self._run_info["number_of_verifications"] += len(new_redescriptions)
                    if accuracy >= self.min_accuracy:
                        new = create_new_redescription([a, b, c, d], (literal, LogicalOperator.DISJUNCTION))
                        candidates[2].append(new)

                    # Formula 4: side or (not literal)
                    if "NOT" in self.operators:
                        a = s(e_11) + c if side == "lhs" else s(e_11) + b
                        b = s(left_card) + self.data.shape[0] - s(lor(left_card)) - a if side == "lhs" else s(land(e_10))
                        c = s(land(e_01)) if side == "lhs" else s(right_card) + self.data.shape[0] - s(lor(right_card)) - a
                        d = s(e_00) - d

                        accuracy = self.quantifier.calculate([a, b, c, d])
                        self._run_info["number_of_verifications"] += len(new_redescriptions)
                        if accuracy >= self.min_accuracy:
                            new = create_new_redescription([a, b, c, d], (literal, LogicalOperator.DISJUNCTION, True))
                            candidates[3].append(new)

            # Save redescription + new attribute to seen redescription to Book-keeping
            new_attribute = [str(attribute)]
            self.book.insert_attributes(
                left_attributes + new_attribute if side == "lhs" else left_attributes,
                right_attributes + new_attribute if side == "rhs" else right_attributes
            )

            # Select only the best redescriptions for each operator extension option
            for bucket in candidates:
                if len(bucket):
                    new_redescriptions.append(sorted(bucket, reverse=True)[0])

        return new_redescriptions

    def _categories(self, attribute: str) -> List[BoolAttribute]:
        """Generates a list of posible categories for a given attribute BoolAttribute instances in the dataset.

        Args:
            attribute (str): The name of the attribute for which to generate posible categories.

        Returns:
            list: A list of BoolAttribute instances representing the possible values of the attribute.
              - If the attribute is of boolean type, returns BoolAttribute instances for both True and False.
              - If the attribute is of categorical type with interval categories, returns BoolAttribute instances for each interval.
              - Otherwise, returns BoolAttribute instances for each unique value of the attribute.
        """
        # User specified: If the attribute is in the category_coefficient dictionary, use the corresponding coefficient generator
        if attribute in self.category_coefficient:
            coefficient = self.category_coefficient[attribute]
        else:
            attribute_dtype = self.data[attribute].dtype
            coefficient = self.category_coefficient[attribute_dtype.name]
        column = self.data[attribute]

        # Select all values based on attribute's data type
        if type(column.dtype) is pd.CategoricalDtype:
            unique = column.cat.categories
            if type(coefficient) is Sequence and column.cat.ordered is False:
                print(f"{colored('Warning:', Colors.RED)} Attribute {attribute} has the Sequence coefficient set, but does not have the specified ordering. Please check Pandas Categorical data Documentation.")
        else:
            unique = column.unique()

        values = coefficient.get(unique)
        return [BoolAttribute(attribute, _unpack(val)) for val in values]

    def _generate_initial_pairs(self) -> List[Rule]:
        """Generates initial pairs of literals from the left-hand side (LHS) and right-hand side (RHS) attributes. This method iterates over all possible pairs of literals from the LHS and RHS attributes, calculates their accuracy, and returns the best ones.

        Returns:
            list: A list of tuples, where each tuple contains a pair of literals (left_literal, right_literal).

        Notes:
            - The method uses binary string representations of the formulas applied to the data to calculate
              the quadruple (contingency table) values.
            - The self.quantifier is used to calculate each pair accuracy and used to determine the top pairs.
            - The method ensures that the list of pairs does not exceed the specified initial_pair_size.
        """
        pairs = []
        for i in self.lhs_attributes:
            left_literals = self._categories(i)

            for j in self.rhs_attributes:
                right_literals = self._categories(j)
                new_pairs = product(left_literals, right_literals)

                for left_literal, right_literal in new_pairs:
                    self._run_info["number_of_verifications"] += 1
                    # Get the binary string representation of the formula applied to the data
                    antecedent_card = get_literal_card(self._cards, left_literal, self._attribute_types)
                    succedent_card = get_literal_card(self._cards, right_literal, self._attribute_types)

                    # Calculate quadruple (contingency table)
                    # a (E_1,1) - number of rows that satisfy both sides
                    a = np.sum(np.logical_and(antecedent_card, succedent_card))
                    # b (E_1,0) - number of rows that satisfy left side but not right side
                    b = np.sum(antecedent_card) - a
                    # c (E_0,1) - number of rows that satisfy right side but not left side
                    c = np.sum(succedent_card) - a
                    # d (E_0,0) - number of rows that satisfy neither side
                    d = self.data.shape[0] - a - b - c

                    # Calculate accuracy for the pair
                    accuracy = self.quantifier.calculate([a, b, c, d])

                    # Skip pairs with low accuracy coefficient
                    if accuracy < self.min_accuracy:
                        continue

                    # Create a new item with the pair and its accuracy
                    item = {
                        "lhs": BoolAttributeQuery(left_literal),
                        "rhs": BoolAttributeQuery(right_literal),
                        "accuracy": accuracy,
                        "quadruple": [a, b, c, d]
                    }

                    self._pair_append(pairs, item)

        # Convert pairs to Rule instances
        pairs = [
            Rule(pair["lhs"], pair["rhs"], [self.quantifier], pair["quadruple"]) for pair in pairs
        ]

        # For the sake of simplicity, we save only the best pairs to book-keeping structure
        # because the generation of new redescriptions is not non-shortening
        # and we don't explore others than those in pairs.
        for p in pairs:
            self.book.insert(p)

        return pairs

    def _pair_append(self, pairs, potential_pair):
        """Safely appends a potential pair to the list of pairs based on accuracy and attribute matching. Only the pairs with the highest accuracy values are retained.

        If redundancy is set to false then if a pair with matching attributes on both sides already exists in the list, it will be replaced only if the new pair has a higher accuracy value.

        Returns:
            list: The updated list of pairs after considering the potential pair.

        Notes:
            The function performs the following steps:
            1. Checks if the potential pair has a higher accuracy than the lowest in the list.
            2. Checks if the potential pair has matching attributes on both sides with any other pair.
                - If it does and has a higher accuracy, it replaces the existing pair.
            3. If the pair does not have matching attributes on both sides with any other pair:
                - Stores the pair if the list is not full.
                - If the list is full, replace the pair with the lowest accuracy in the list.
        """
        if len(pairs) == 0:
            pairs.append(potential_pair)
            return

        # Get the pair with the lowest Jaccard coefficient
        min_pair = min(pairs, key=lambda x: x["accuracy"])

        # If the list is full, check if the potential pair has a higher Jaccard coefficient than the lowest in the list
        if len(pairs) == self.initial_pair_size and potential_pair["accuracy"] < min_pair["accuracy"]:
            return

        # Check if the potential_pair has matching attributes on both sides with any other pair
        if not self.redundancy:
            for pair in pairs:
                if (pair["lhs"].attributes == potential_pair["lhs"].attributes and
                        pair["rhs"].attributes == potential_pair["rhs"].attributes):
                    # If the potential_pair has a higher Jaccard coefficient than other with same sides, replace the existing pair
                    if pair["accuracy"] < potential_pair["accuracy"]:
                        pairs.remove(pair)
                        pairs.append(potential_pair)
                    return

        # Store the pair if the list is not full
        if len(pairs) < self.initial_pair_size or self.initial_pair_size == 0:
            pairs.append(potential_pair)
            return

        # Store the pair if it has a higher Jaccard coefficient than the lowest in the list
        pairs.remove(min_pair)
        pairs.append(potential_pair)


class BookKeeping():
    "Structure for book-keeping already generated redescription. It store only the specific attributes of the seen redescription."
    def __init__(self, miner: ReReMiMiner, rhs_attributes: List[str], lhs_attributes: List[str]):
        self.miner = miner
        prefix_length = len(lhs_attributes)
        suffix_length = len(rhs_attributes)
        self.splitline = prefix_length
        self.seen = BitwiseTrie(bit_length=prefix_length + suffix_length)

    def insert(self, redescription: Rule):
        "Mark redescription as seen."
        self.insert_attributes(
            redescription.lhs.attributes,
            redescription.rhs.attributes
        )

    def insert_attributes(self, left_attributes, right_attributes):
        "Mark redescription represented as left and right attributes as seen."
        prefix = self.transform("lhs", left_attributes)
        suffix = self.transform("rhs", right_attributes)

        self.seen.insert(prefix + suffix)

    def search(self, side, redescription: Rule):
        "Return all seen queries that was generated with one step extension on one side from query."
        prefix = self.transform("lhs", redescription.lhs.attributes)
        suffix = self.transform("rhs", redescription.rhs.attributes)

        if side == "lhs":
            prefix = prefix.replace("0", "?")
        elif side == "rhs":
            suffix = suffix.replace("0", "?")

        mask = prefix + suffix
        seen_masks = self.seen.search_with_mask(mask)
        return map(lambda x: x[:self.splitline] if side == "lhs" else x[self.splitline:], seen_masks)

    def transform(self, side, attributes) -> str:
        "Transform list of attribute (query) to string of bites."
        def f(a):
            # Check if a is in attributes, then return "1", otherwise "0"
            return str(int(a in attributes))

        if side == "lhs":
            return "".join([f(a) for a in self.miner.lhs_attributes])
        elif side == "rhs":
            return "".join([f(a) for a in self.miner.rhs_attributes])
        else:
            raise ValueError("Side must be either 'lhs' or 'rhs'.")
