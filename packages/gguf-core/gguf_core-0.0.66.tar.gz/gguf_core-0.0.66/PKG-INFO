Metadata-Version: 2.1
Name: gguf-core
Version: 0.0.66
Summary: a simple way to interact llama with gguf
Author-email: calcuis <info@calcu.io>
Description-Content-Type: text/markdown
Classifier: License :: OSI Approved :: MIT License
Requires-Dist: llama-core >=0.3.3
Project-URL: Homepage, https://gguf.us
Project-URL: Issues, https://github.com/calcuis/gguf-core/issues
Project-URL: Repository, https://github.com/calcuis/gguf-core

### GGUF core
[<img src="https://raw.githubusercontent.com/calcuis/gguf-core/master/gguf.gif" width="128" height="128">](https://github.com/calcuis/gguf-core)
[![Static Badge](https://img.shields.io/badge/core-release-orange?logo=github)](https://github.com/calcuis/gguf-core/releases)

This package is a GGUF (GPT-Generated Unified Format) file caller.
#### install the caller via pip/pip3 (once only):
```
pip install gguf-core
```
#### update the caller (if not in the latest version) by:
```
pip install gguf-core --upgrade
```
### user manual
This is a cmd-based (command line) package, you can find the user manual by adding the flag -h or --help.
```
gguf -h
```
#### check current version
```
gguf -v
```
#### cli connector
with command-line interface
```
gguf c
```
#### gui connector
with graphical user interface
```
gguf g
```
#### vision connector (beta)
with vision model supported
```
gguf v
```
#### interface selector
selection menu for connector interface(s) above
```
gguf i
```
#### metadata reader
read model metadata for detail(s)
```
gguf r
```
or try model analyzor (beta)
```
gguf a
```
GGUF file(s) in the current directory will automatically be detected by the caller.
#### get feature
get GGUF from URL; clone/download it to the current directory
```
gguf get [url]
```
#### sample model list
You can either use the get feature above or opt a sample GGUF straight from the sample list by:
```
gguf s
```
#### gguf splitter
Split gguf into part(s) by:
```
gguf split
```
#### gguf merger
Merge all gguf into one by:
```
gguf merge
```
#### prompt generator (beta)
Generate bulk prompt/descriptor(s) by:
```
gguf prompt
```
#### gguf comfy (beta)
Download ComfyUI GGUF portable package with gguf node by:
```
gguf comfy
```
#### gguf node (beta)
Download gguf node only by:
```
gguf node
```
#### gguf pack (beta)
Download gguf pack by:
```
gguf pack
```
#### pdf analyzor (beta)
You can now load your PDF file(s) straight into the model for generating digested summary; try it out by:
```
gguf p
```
#### wav analyzor (offline)
You can speak/talk straight to GGUF right away; prompt WAV(s) into the model for feedback; try it out by:
```
gguf f
```
#### wav analyzor (online)
more accurate (via google Open api); Internet access needed; try it out by:
```
gguf o
```
#### launch to page/container (gguf.org)
```
gguf org
```
#### launch to page/container (gguf.io)
```
gguf io
```
#### launch to page/container (gguf.us)
```
gguf us
```
